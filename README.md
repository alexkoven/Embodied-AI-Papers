# Embodied-AI-Papers

This repository contains the latest research papers for embodied AI organized by categories. For more detailed analysis, follow me [here](https://x.com/alexkoven).

## Table of Contents

- [Benchmarks](#benchmarks) (31 papers)
- [Cross-Embodiment](#cross-embodiment) (4 papers)
- [Datasets](#datasets) (9 papers)
- [Diffusion & Flow](#diffusion-and-flow) (19 papers)
- [Finetuning](#finetuning) (4 papers)
- [Humanoid](#humanoid) (30 papers)
- [Imitation Learning](#imitation-learning) (10 papers)
- [Manipulation](#manipulation) (37 papers)
- [Modeling & World Models](#modeling-and-world-models) (18 papers)
- [RL](#rl) (32 papers)
- [Robot Control](#robot-control) (19 papers)
- [Robot Data](#robot-data) (12 papers)
- [Robotics Platforms](#robotics-platforms) (12 papers)
- [Safety and Robustness](#safety-and-robustness) (6 papers)
- [Sim-to-Real & Real-to-Sim](#sim-to-real-and-real-to-sim) (6 papers)
- [Simulation](#simulation) (19 papers)
- [Survey](#survey) (5 papers)
- [Tactile](#tactile) (3 papers)
- [VLM & VLA](#vlm-and-vla) (57 papers)

## Benchmarks

*31 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [RoboEval - Where Robotic Manipulation Meets Structured and Scalable Evaluation](https://arxiv.org/abs/2507.00435) | 2025-07-01 | Benchmarks, Manipulation | The paper introduces RoboEval, a structured evaluation framework that decomposes bimanual manipulation tasks into skill-specific stages, enhancing the diagnostic capabilities of evaluation metrics.... |
| [RoboArena Distributed Real-World Evaluation of Generalist Robot Policies](https://arxiv.org/html/2506.18123v1) | 2025-06-22 | Benchmarks, Manipulation | The paper introduces RoboArena, a novel decentralized framework that allows for crowd-sourced evaluations of generalist robot policies. Key contributions include the implementation of a pairwise co... |
| [RoboVerse Towards a Unified Platform, Dataset and Benchmark for Scalable and Generalizable Robot Learning](https://arxiv.org/html/2504.18904v1) | 2025-04-26 | Benchmarks, Datasets, Simulation | The primary contributions of this paper include the introduction of RoboVerse, a comprehensive framework that integrates a simulation platform, a large-scale synthetic dataset, and unified benchmar... |
| [AutoEval Autonomous Evaluation of Generalist Robot Manipulation Policies in the Real World](https://arxiv.org/html/2503.24278v2) | 2025-03-31 | Benchmarks, Manipulation | The primary contribution of the paper is the introduction of AutoEval, a system designed for autonomous evaluation of robot policies that minimizes human intervention. AutoEval enables continuous e... |
| [Towards Generalizable Vision-Language Robotic Manipulation A Benchmark and LLM-guided 3D Policy](https://arxiv.org/html/2410.01345v2) | 2025-03-01 | Benchmarks, VLM & VLA | The key contributions include the introduction of GemBench, a novel benchmark designed to assess the generalization abilities of vision-language robotic manipulation policies across four levels of ... |
| [OGBench - Benchmarking Offline Goal-Conditioned RL](https://seohong.me/projects/ogbench/) | 2025-02-13 | Benchmarks | The paper introduces OGBench, a novel benchmark designed specifically for offline goal-conditioned RL, featuring 85 datasets and 410 tasks that encompass various algorithmic challenges. A significa... |
| [Mimicking-Bench A Benchmark for Generalizable Humanoid-Scene Interaction Learning via Human Mimicking](https://arxiv.org/html/2412.17730v1) | 2024-12-23 | Benchmarks, Humanoid | The primary contributions of this work include the introduction of Mimicking-Bench, a comprehensive benchmark designed for generalizable humanoid-scene interaction learning, which incorporates a la... |
| [FMB - a Functional Manipulation Benchmark for Generalizable Robotic Learning](https://arxiv.org/html/2401.08553v3) | 2024-09-03 | Benchmarks, Manipulation | The primary contributions of the paper include the introduction of the Functional Manipulation Benchmark (FMB), which consists of a diverse set of 3D-printed objects designed for practical replicat... |
| [Towards Open-World Mobile Manipulation in Homes Lessons from the Neurips 2023 HomeRobot Open Vocabulary Mobile Manipulation Challenge](https://arxiv.org/html/2407.06939v1) | 2024-07-09 | Benchmarks | The paper contributes a new benchmark for open-vocabulary mobile manipulation, termed HomeRobot OVMM, which aims to evaluate robotic performance in both simulation and real-world contexts. The auth... |
| [HumanoidBench Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation](https://arxiv.org/html/2403.10506v2) | 2024-06-18 | Benchmarks, Humanoid | The primary contributions of the paper include the introduction of HumanoidBench, a high-dimensional benchmark featuring 27 distinct tasks that challenge state-of-the-art reinforcement learning alg... |
| [RoboCasa Large-Scale Simulation of Everyday Tasks for Generalist Robots](https://arxiv.org/html/2406.02523v1) | 2024-06-04 | Benchmarks, Simulation | The primary contributions of the paper include the introduction of RoboCasa, which features diverse kitchen scenes, thousands of 3D object assets, and a comprehensive set of 100 tasks that encompas... |
| [The Colosseum A Benchmark for Evaluating Generalization for Robotic Manipulation](https://arxiv.org/html/2402.08191v2) | 2024-05-28 | Benchmarks | The primary contributions include the introduction of "The Colosseum", a novel benchmark that systematically evaluates 20 diverse manipulation tasks across 14 axes of environmental perturbations. T... |
| [Evaluating Real-World Robot Manipulation Policies in Simulation (SimplerEnv on Github)](https://arxiv.org/html/2405.05941v1) | 2024-05-09 | Benchmarks | Key contributions include the introduction of SIMPLER, a suite of simulated environments designed for manipulation policy evaluation that does not require full fidelity. The paper demonstrates that... |
| [DROID - A Large-Scale In-The-Wild Robot Manipulation Dataset](https://arxiv.org/html/2403.12945v2) | 2024-03-19 | Benchmarks, Datasets, Manipulation | The primary contributions of the paper include the introduction of DROID (Distributed Robot Interaction Dataset), which contains 76,000 demonstration trajectories across 564 scenes and 86 tasks. Th... |
| [SCENEREPLICA - Benchmarking Real-World Robot Manipulation by Creating Replicable Scenes](https://arxiv.org/pdf/2306.15620) | 2024-03-11 | Benchmarks | The paper introduces SceneReplica, a novel benchmark that utilizes 16 YCB objects in 20 distinct scenes for pick-and-place tasks. The key contributions include the development of an easy-to-use too... |
| [RAMP -  A Benchmark for Evaluating Robotic Assembly Manipulation and Planning](https://arxiv.org/pdf/2305.09644) | 2023-11-08 | Benchmarks | RAMP presents a challenge-driven, accessible, and open-ended benchmark that includes a diverse set of predefined assemblies categorized by difficulty (easy, medium, hard). It introduces 3D printed ... |
| [Train Offline, Test Online - A Real Robot Learning Benchmark](https://pdf2md.morethan.io/) | 2023-06-30 | Benchmarks | The primary contributions of the paper include the introduction of a novel benchmark called Train Offline, Test Online (TOTO), which aims to provide remote access to shared robotic hardware for eva... |
| [LIBERO – Benchmarking Knowledge Transfer in Lifelong Robot Learning](https://libero-project.github.io/main) | 2023-06-05 | Benchmarks, Datasets | The primary contributions of the paper include the introduction of the LIBERO benchmark, which provides a structured framework for evaluating lifelong learning in robotics. The authors present meth... |
| [FurnitureBench - Reproducible Real-World Benchmark for Long-Horizon Complex Manipulation](https://pdf2md.morethan.io/) | 2023-05-22 | Benchmarks | The primary contributions of this paper include the introduction of FurnitureBench, a novel benchmark designed for evaluating robotic manipulation in furniture assembly tasks. The benchmark is char... |
| [DexArt - Benchmarking Generalizable Dexterous Manipulation with Articulated Objects](https://arxiv.org/pdf/2305.05706) | 2023-05-09 | Benchmarks, Simulation | The primary contributions of the paper include the introduction of the DexArt benchmark, specifically designed for evaluating dexterous manipulation of articulated objects. This benchmark comprises... |
| [RB2 - Robotic Manipulation Benchmarking with aTwist](https://arxiv.org/pdf/2203.08098) | 2022-10-31 | Benchmarks | The paper introduces the Ranking-Based Robotics Benchmark (RB2), which aims to provide a more flexible and replicable framework for evaluating robotic manipulation algorithms. It emphasizes the sig... |
| [Interactive Language - Talking to Robots in Real Time](https://interactive-language.github.io/) | 2022-10-12 | Benchmarks | The primary contributions include the development of a novel framework that leverages a large-scale dataset of language-annotated trajectories to train robots in a way that significantly improves t... |
| [AI2-THOR - An Interactive 3D Environment for Visual AI](https://arxiv.org/abs/1712.05474) | 2022-08-26 | Benchmarks, Simulation | The primary contributions of the paper include the introduction of AI2-THOR, a framework that allows for the simulation of near photo-realistic 3D environments featuring diverse interactive objects... |
| [CALVIN - A Benchmark for Language-Conditioned Policy Learning for Long-Horizon Robot Manipulation Tasks](https://arxiv.org/abs/2112.03227) | 2022-07-13 | Benchmarks, Simulation | The paper introduces CALVIN, an open-source benchmark designed for learning long-horizon language-conditioned tasks, which enables robots to perform intricate manipulation actions based on natural ... |
| [Real Robot Challenge - A Robotics Competition in the Cloud](https://pdf2md.morethan.io/) | 2022-06-10 | Benchmarks | The primary contributions of this paper include the establishment of a remote access platform for dexterous manipulation, which allows researchers to utilize robotic systems without the need for ex... |
| [BEHAVIOR - Benchmark for Everyday Household Activities in Virtual, Interactive, and Ecological Environments](https://pdf2md.morethan.io/) | 2021-08-06 | Benchmarks | The paper introduces the BEHAVIOR benchmark, consisting of 100 household activities defined using a novel predicate logic-based representation language called BDDL. Key contributions include the de... |
| [robosuite - A Modular Simulation Framework and Benchmark for Robot Learning](https://arxiv.org/html/2009.12293v3) | 2020-09-25 | Benchmarks | This work introduces robosuite, a simulation framework designed to enhance the flexibility and accessibility of robotics research. Key contributions include the implementation of a standardized set... |
| [RLBench - The Robot Learning Benchmark & Learning Environment](https://pdf2md.morethan.io/) | 2019-09-26 | Benchmarks, Simulation | The paper introduces RLBench, a novel benchmark and learning environment designed for robot learning research. Key contributions include the provision of 100 unique, hand-designed tasks that vary i... |
| [REPLAB - A Reproducible Low-Cost Arm Benchmark Platform for Robotic Learning](https://pdf2md.morethan.io/) | 2019-05-17 | Benchmarks | The primary contributions of the paper include the introduction of the REPLAB platform, a low-cost, reproducible hardware setup designed for benchmarking robotic manipulation tasks. The authors pre... |
| [DeepMind Control Suite](https://pdf2md.morethan.io/) | 2018-01-03 | Benchmarks, Simulation | The primary contributions of the paper are the introduction of the DeepMind Control Suite, which includes a wide range of well-defined continuous control tasks, and the establishment of a unified r... |
| [Benchmarking in Manipulation Research - The YCB Object and Model Set and Benchmarking Protocols](https://pdf2md.morethan.io/) | 2015-02-10 | Benchmarks | The paper's primary contributions include the introduction of the YCB Object and Model set, which encompasses a diverse array of everyday objects designed to challenge various aspects of robotic ma... |

## Cross-Embodiment

*4 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [Is Diversity All You Need for Scalable Robotic Manipulation](https://arxiv.org/html/2507.06219v1) | 2025-07-08 | Cross-Embodiment, Robot Data | The paper presents three main contributions: (1) It establishes that task diversity is more critical than the sheer number of demonstrations per task for effective transfer to new scenarios, sugges... |
| [Latent Action Diffusion for Cross-Embodiment Manipulation](https://arxiv.org/html/2506.14608v1) | 2025-06-17 | Cross-Embodiment, Diffusion & Flow | The authors propose a novel method for learning a cross-end-effector latent action space that allows for semantic alignment of diverse robotic actions. They introduce a framework that leverages con... |
| [X-Sim Cross-Embodiment Learning via Real-to-Sim-to-Real](https://arxiv.org/html/2505.07096v3) | 2025-05-11 | Cross-Embodiment, Diffusion & Flow, Sim-to-Real & Real-to-Sim | The paper introduces X-Sim, a novel real-to-sim-to-real framework that leverages object motion as a transferable signal for training robot policies in simulation. Key contributions include the deve... |
| [Towards Embodiment Scaling Laws in Robot Locomotion](https://arxiv.org/html/2505.05753v1) | 2025-05-09 | Cross-Embodiment, Robotics Platforms | The primary contributions of this paper include the development of a large-scale dataset, GenBot-1K, consisting of approximately 1,000 diverse robot embodiments, and the introduction of a two-stage... |

## Datasets

*9 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [Dex1B Learning with 1B Demonstrations for Dexterous Manipulation](https://arxiv.org/html/2506.17198v1) | 2025-05-20 | Datasets, Manipulation | The paper introduces Dex1B, a groundbreaking dataset comprising one billion high-quality demonstrations for dexterous manipulation tasks. Key contributions include a novel generative model that int... |
| [DexWild Dexterous Human Interactions for In-the-Wild Robot Policies](https://arxiv.org/html/2505.07813v1) | 2025-05-12 | Datasets | The paper introduces DexWild, a novel data collection system that empowers untrained human operators to gather large amounts of interaction data using their own hands, achieving a significant speed... |
| [RoboVerse Towards a Unified Platform, Dataset and Benchmark for Scalable and Generalizable Robot Learning](https://arxiv.org/html/2504.18904v1) | 2025-04-26 | Benchmarks, Datasets, Simulation | The primary contributions of this paper include the introduction of RoboVerse, a comprehensive framework that integrates a simulation platform, a large-scale synthetic dataset, and unified benchmar... |
| LeRobot goes to driving school - World’s largest open-source self-driving dataset | 2025-03-11 | Datasets | This paper introduces the Learning to Drive (L2D) dataset, which offers over 90 terabytes of multimodal driving data, incorporating 6 camera views and natural language instructions for various driv... |
| [GRIP - A General Robotic Incremental Potential Contact Simulation Dataset for Unified Deformable-Rigid Coupled Grasping](https://arxiv.org/html/2503.05020v2) | 2025-03-06 | Datasets, Manipulation, Robot Data | The primary contributions of this paper include the introduction of the GRIP dataset, which encompasses 1,200 objects and 100,000 grasp poses, facilitating research in both soft and rigid grasping.... |
| [DROID - A Large-Scale In-The-Wild Robot Manipulation Dataset](https://arxiv.org/html/2403.12945v2) | 2024-03-19 | Benchmarks, Datasets, Manipulation | The primary contributions of the paper include the introduction of DROID (Distributed Robot Interaction Dataset), which contains 76,000 demonstration trajectories across 564 scenes and 86 tasks. Th... |
| [BridgeData V2 - A Dataset for Robot Learning at Scale](https://arxiv.org/html/2308.12952v3) | 2024-01-17 | Datasets | The primary contributions of the paper include the creation of BridgeData V2, which encompasses 60,096 diverse robotic manipulation trajectories across 24 environments, significantly expanding the ... |
| [Open X-Embodiment Robotic Learning Datasets and RT-X Models](https://arxiv.org/html/2310.08864v8) | 2023-10-13 | Datasets, VLM & VLA | The authors present the Open X-Embodiment Repository, a comprehensive dataset containing over 1 million trajectories from 22,222 robotic embodiments across 21 institutions, which facilitates the ex... |
| [LIBERO – Benchmarking Knowledge Transfer in Lifelong Robot Learning](https://libero-project.github.io/main) | 2023-06-05 | Benchmarks, Datasets | The primary contributions of the paper include the introduction of the LIBERO benchmark, which provides a structured framework for evaluating lifelong learning in robotics. The authors present meth... |

## Diffusion & Flow

*19 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [VITA Vision-to-Action Flow Matching Policy](https://arxiv.org/html/2507.13231v1) | 2025-07-17 | Diffusion & Flow | The paper introduces VITA (Vision-to-Action flow matching), a novel framework that directly maps latent visual representations to latent actions without the need for extra conditioning mechanisms. ... |
| [Steering Your Diffusion Policy with Latent Space Reinforcement Learning](https://arxiv.org/html/2506.15799v1) | 2025-06-18 | Diffusion & Flow, RL | The primary contribution of the paper is the introduction of diffusion steering via reinforcement learning (Dsrl), a novel approach that facilitates fast autonomous adaptation of BC-trained policie... |
| [Latent Action Diffusion for Cross-Embodiment Manipulation](https://arxiv.org/html/2506.14608v1) | 2025-06-17 | Cross-Embodiment, Diffusion & Flow | The authors propose a novel method for learning a cross-end-effector latent action space that allows for semantic alignment of diverse robotic actions. They introduce a framework that leverages con... |
| [Diffusion Guidance Is a Controllable Policy Improvement Operator](https://arxiv.org/html/2505.23458v1) | 2025-05-29 | Diffusion & Flow, RL | This paper presents the CFGRL framework, which innovatively connects diffusion model guidance with RL policy improvement. Notable contributions include a novel method for policy extraction that all... |
| [FLEX A Backbone for Diffusion-Based Modeling of Spatio-temporal Physical Systems](https://arxiv.org/html/2505.17351v1) | 2025-05-23 | Diffusion & Flow, RL | The paper introduces FLEX (FLow EXpert), a novel backbone architecture that combines U-Net and Transformer elements to enhance both local detail and global dependency representation. Key contributi... |
| [Diffusion Model Predictive Control](https://arxiv.org/html/2410.05364v2) | 2025-05-22 | Diffusion & Flow, Robot Control | The primary contributions of the paper include the development of D-MPC, which utilizes multi-step action proposals and dynamics learned through diffusion models to enhance performance in offline p... |
| [Learning Long-Context Diffusion Policies via Past-Token Prediction](https://arxiv.org/html/2505.09561v2) | 2025-05-19 | Diffusion & Flow | The primary contributions of this paper are the introduction of Past-Token Prediction (PTP) as an auxiliary learning task, which encourages policies to predict past actions in addition to future on... |
| [Conditioning Matters Training Diffusion Policies is Faster Than You Think](https://arxiv.org/html/2505.11123v1) | 2025-05-16 | Diffusion & Flow, RL | The primary contribution of this paper is the introduction of Cocos, a novel conditional flow matching approach that modifies the source distribution to be condition-dependent. This method enhances... |
| [X-Sim Cross-Embodiment Learning via Real-to-Sim-to-Real](https://arxiv.org/html/2505.07096v3) | 2025-05-11 | Cross-Embodiment, Diffusion & Flow, Sim-to-Real & Real-to-Sim | The paper introduces X-Sim, a novel real-to-sim-to-real framework that leverages object motion as a transferable signal for training robot policies in simulation. Key contributions include the deve... |
| [Video Prediction Policy - A Generalist Robot Policy with Predictive Visual Representations](https://arxiv.org/html/2412.14803) | 2025-05-04 | Diffusion & Flow, RL | The primary contributions of the paper include the introduction of the Video Prediction Policy (VPP), which learns implicit inverse dynamics conditioned on future visual representations. The author... |
| ArticuBot Learning Universal Articulated Object Manipulation Policy via Large Scale Simulation | 2025-05-01 | Diffusion & Flow, Manipulation, Sim-to-Real & Real-to-Sim | The primary contributions of this paper include the introduction of ArticuBot, a system that leverages a single learned policy to open diverse categories of articulated objects. The authors propose... |
| [You Only Teach Once Learn One-Shot Bimanual Robotic Manipulation from Video Demonstrations](https://arxiv.org/html/2501.14208v2) | 2025-04-27 | Diffusion & Flow, Manipulation | The primary contributions of the paper are threefold: firstly, the introduction of a method for extracting and injecting dual-arm movements from single-shot human demonstrations, facilitating rapid... |
| [Latent Diffusion Planning for Imitation Learning](https://arxiv.org/html/2504.16925v1) | 2025-04-23 | Diffusion & Flow | The primary contributions of the paper include the introduction of LDP, which modularly separates the planning and action extraction processes, allowing it to leverage diverse data types. The key m... |
| [NIL - No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models](https://arxiv.org/html/2503.10626v1) | 2025-03-13 | Diffusion & Flow, Imitation Learning | The primary contributions of the paper include the introduction of No-data Imitation Learning (NIL), which employs pretrained video diffusion models to generate reference videos on-the-fly for trai... |
| [Reactive Diffusion Policy Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation](https://arxiv.org/html/2503.02881v3) | 2025-03-03 | Diffusion & Flow, Imitation Learning, Manipulation, Tactile | The primary contributions of this work include the development of the TactAR teleoperation system, which facilitates real-time tactile feedback through Augmented Reality, and the Reactive Diffusion... |
| [IMLE Policy Fast and Sample Efficient Visuomotor Policy Learning via Implicit Maximum Likelihood Estimation](https://imle-policy.github.io/) | 2025-02-17 | Diffusion & Flow | The paper introduces IMLE Policy, a novel approach based on Implicit Maximum Likelihood Estimation (IMLE) that significantly improves learning efficiency from minimal demonstrations. The authors de... |
| [Full-Order Sampling-Based MPC for Torque-Level Locomotion Control via Diffusion-Style Annealing](https://arxiv.org/html/2409.15610v1) | 2024-09-23 | Diffusion & Flow, Robot Control | The primary contributions of the paper include the introduction of DIAL-MPC (Diffusion-Inspired Annealing for Legged MPC), a novel sampling-based MPC framework that incorporates a diffusion-style a... |
| [SELF-IMPROVING DIFFUSION MODELS WITH SYNTHETIC DATA](https://pdf2md.morethan.io/) | 2024-08-29 | Diffusion & Flow | The paper introduces Self-Improving Diffusion Models with Synthetic Data (SIMS), which innovatively uses self-generated synthetic data to guide model training away from the pitfalls of synthetic da... |
| [Diffusion Policy Visuomotor Policy Learning via Action Diffusion](https://arxiv.org/html/2303.04137v5) | 2024-03-14 | Diffusion & Flow, RL | The authors introduce the Diffusion Policy framework, which formulates robot behaviors as a conditional denoising diffusion process. Key contributions include the integration of receding-horizon co... |

## Finetuning

*4 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [Fine-Tuning Vision-Language-Action Models Optimizing Speed and Success](https://arxiv.org/html/2502.19645v2) | 2025-04-28 | Finetuning, VLM & VLA | The authors introduce an Optimized Fine-Tuning (OFT) approach that integrates parallel decoding, action chunking, continuous action representations, and a simple L1 regression objective. These meth... |
| [ConRFT A Reinforced Fine-tuning Method for VLA Models via Consistency Policy](https://arxiv.org/html/2502.05450v2) | 2025-04-14 | Finetuning, RL, VLM & VLA | The paper introduces a novel reinforced fine-tuning approach named ConRFT, which integrates both offline and online fine-tuning stages using a unified consistency-based training objective. Key cont... |
| [Echo Chamber RL Post-training Amplifies Behaviors Learned in Pretraining](https://arxiv.org/html/2504.07912v1) | 2025-04-10 | Finetuning, RL | The paper presents a systematic end-to-end study of RL fine-tuning on models trained from scratch using various mixtures of fully open datasets. Key contributions include demonstrating that RL cons... |
| [RLDG Robotic Generalist Policy Distillation via Reinforcement Learning](https://arxiv.org/html/2412.09858v1) | 2024-12-13 | Finetuning | The primary technical contributions of the paper include the introduction of RLDG, a novel method that utilizes RL to generate high-quality training data for fine-tuning generalist policies. The au... |

## Humanoid

*30 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [UniTracker Learning Universal Whole-Body Motion Tracker for Humanoid Robots](https://arxiv.org/html/2507.07356v1) | 2025-07-10 | Humanoid | The primary contributions of this work include the introduction of UniTracker, a framework that integrates a Conditional Variational Autoencoder (CVAE) into the student policy. This approach allows... |
| [Hierarchical Vision-Language Planning for Multi-Step Humanoid Manipulation](https://arxiv.org/html/2506.22827v1) | 2025-06-28 | Humanoid | The paper presents multiple key contributions, including the development of a three-layer hierarchical framework that combines a low-level reinforcement learning (RL) controller, mid-level imitatio... |
| [LeVERB Humanoid Whole-Body Control with Latent Vision-Language Instruction](https://arxiv.org/html/2506.13751v2) | 2025-06-19 | Humanoid, Robot Control | The paper introduces LeVERB, a hierarchical framework that allows for latent instruction-following in humanoid WBC. Key contributions include a novel dual-process architecture that separates high-l... |
| [From Experts to a Generalist Toward General Whole-Body Control for Humanoid Robots](https://arxiv.org/html/2506.12779v2) | 2025-06-19 | Humanoid, Robot Control | The paper introduces the BumbleBee (BB) framework, which combines motion clustering with sim-to-real adaptation to create a generalist controller that maintains agility and robustness across variou... |
| [GMT General Motion Tracking for Humanoid Whole-Body Control](https://arxiv.org/html/2506.14770v1) | 2025-06-17 | Humanoid, RL | The primary contributions of this work include the introduction of the Adaptive Sampling strategy, which optimally balances the training of easier and more challenging motions, and a Motion Mixture... |
| [KungfuBot - Physics-Based Humanoid Whole-Body Control for Learning Highly-Dynamic Skills](https://kungfu-bot.github.io/) | 2025-06-15 | Humanoid, Robot Control | The primary contributions include a novel physics-based humanoid control framework that integrates multi-step motion processing with adaptive motion tracking. Methodologically, the authors propose ... |
| [RL from Physical Feedback Aligning Large Motion Models with Humanoid Control](https://arxiv.org/html/2506.12769v1) | 2025-06-15 | Humanoid | The primary contributions of the paper include the introduction of the Reinforcement Learning from Physical Feedback (RLPF) framework, which integrates physics-aware motion evaluation with text-con... |
| [SkillBlender Towards Versatile Humanoid Whole-Body Loco-Manipulation via Skill Blending](https://arxiv.org/html/2506.09366v1) | 2025-06-11 | Humanoid, Symbolic AI | SkillBlender is introduced as a hierarchical reinforcement learning framework that allows for versatile humanoid loco-manipulation through a pretrain-then-blend strategy, significantly reducing the... |
| [SLAC Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL](https://arxiv.org/html/2506.04147v2) | 2025-06-07 | Humanoid, RL | The primary contributions of the paper include the introduction of SLAC (Simulation-Pretrained Latent Action Space), a framework that allows for the pretraining of a latent action space in low-fide... |
| [One Policy but Many Worlds - A Scalable Unified Policy for Versatile Humanoid Locomotion](https://arxiv.org/html/2505.18780v2) | 2025-06-03 | Humanoid, RL | The primary contribution of this work is the introduction of DreamPolicy, a unified framework that integrates offline data and employs a terrain-aware autoregressive diffusion planner to synthesize... |
| FastTD3 Simple, Fast, and Capable Reinforcement Learning for Humanoid Control | 2025-05-29 | Humanoid, RL | The paper introduces FastTD3, a novel RL algorithm designed for increased efficiency in training humanoid robots. It incorporates parallel simulation, large-batch updates, and a distributional crit... |
| [HuB Learning Extreme Humanoid Balance](https://arxiv.org/html/2505.07294v1) | 2025-05-12 | Humanoid, Robot Control | The primary contributions of the paper include the introduction of the HuB framework, which integrates reference motion refinement, balance-aware policy learning, and sim-to-real robustness trainin... |
| [JAEGER - Dual-Level Humanoid Whole-Body Controller](https://arxiv.org/html/2505.06584v1) | 2025-05-10 | Humanoid | The paper introduces JAEGER, a dual-level WBC controller that innovatively separates upper and lower body control, thus reducing mutual interference and enhancing task-specific performance. Key con... |
| [PyRoki A Modular Toolkit for Robot Kinematic Optimization](https://pyroki-toolkit.github.io/) | 2025-05-06 | Humanoid | The primary contribution of PyRoki is its modular architecture that allows for composable kinematic variables and costs, enabling seamless integration of various optimization tasks. The toolkit dem... |
| [AMO Adaptive Motion Optimization for Hyper-Dexterous Humanoid Whole-Body Control](https://arxiv.org/html/2505.03738v1) | 2025-05-06 | Humanoid, Robot Control | The paper introduces Adaptive Motion Optimization (AMO), which integrates sim-to-real reinforcement learning (RL) with trajectory optimization. Key contributions include a hybrid motion synthesis a... |
| [LangWBC Language-directed Humanoid Whole-Body Control via End-to-end Learning](https://arxiv.org/html/2504.21738v1) | 2025-04-30 | Humanoid, Robot Control | The paper presents a novel end-to-end framework called LangWBC, which directly maps natural language commands to physical actions. A significant contribution is the use of a Conditional Variational... |
| [Learning Getting-Up Policies for Real-World Humanoid Robots](https://arxiv.org/html/2502.12152v2) | 2025-04-27 | Humanoid, Robot Control | The paper presents several key contributions, including the development of a novel two-stage reinforcement learning framework named HumanUP, which effectively learns getting-up policies from divers... |
| [Demonstrating Berkeley Humanoid Lite An Open-source, Accessible, and Customizable 3D-printed Humanoid Robot](https://arxiv.org/html/2504.17249v1) | 2025-04-24 | Humanoid, Robotics Platforms | The primary contributions include the design of Berkeley Humanoid Lite, a mid-scale humanoid robot that utilizes modular 3D-printed components, making it both accessible and customizable. The autho... |
| [Learning Humanoid Standing-up Control across Diverse Postures](https://arxiv.org/html/2502.08378v2) | 2025-04-19 | Humanoid, RL, Robot Control | The paper presents the HoST framework, a reinforcement learning-based solution that learns standing-up control from scratch, enabling posture-adaptive motions without predefined trajectories. Key c... |
| [A Unified and General Humanoid Whole-Body Controller for Versatile Locomotion](https://arxiv.org/html/2502.03206v3) | 2025-04-12 | Humanoid, Robot Control | The primary contributions of the paper are the introduction of HugWBC, a unified whole-body controller that supports various locomotion behaviors with a single policy. The method employs a general ... |
| [HOVER Versatile Neural Whole-Body Controller for Humanoid Robots](https://arxiv.org/html/2410.21229v2) | 2025-03-06 | Humanoid, Robot Control | The primary contributions include the introduction of HOVER, a multi-mode policy distillation framework that consolidates diverse control modes into a single policy, enabling efficient transitions ... |
| [InterMimic Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions](https://arxiv.org/html/2502.20390v1) | 2025-02-27 | Humanoid, Robot Control | The primary contributions of the paper include the introduction of the InterMimic framework, which integrates a teacher-student policy distillation approach to improve motion imitation from imperfe... |
| [HOMIE Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit](https://arxiv.org/html/2502.13013v2) | 2025-02-18 | Humanoid, Robot Control | The primary contributions of the paper include the introduction of HOMIE, a semi-autonomous teleoperation system that integrates a reinforcement learning (RL) policy designed for body control mappe... |
| [ToddlerBot Open-Source ML-Compatible Humanoid Platform for Loco-Manipulation](https://toddlerbot.github.io/) | 2025-02-05 | Humanoid, Robotics Platforms | ToddlerBot introduces a novel platform characterized by its low-cost, open-source architecture, which allows for high-fidelity digital twin modeling. The platform features a plug-and-play calibrati... |
| [Humanoid Locomotion and Manipulation Current Progress and Challenges in Control, Planning, and Learning co-corresponding authors](https://arxiv.org/html/2501.02116v1) | 2025-01-03 | Humanoid, Survey | The primary contributions of the paper include the introduction of a unified framework that integrates model-based control with learning-based approaches, allowing for improved performance in loco-... |
| [Mimicking-Bench A Benchmark for Generalizable Humanoid-Scene Interaction Learning via Human Mimicking](https://arxiv.org/html/2412.17730v1) | 2024-12-23 | Benchmarks, Humanoid | The primary contributions of this work include the introduction of Mimicking-Bench, a comprehensive benchmark designed for generalizable humanoid-scene interaction learning, which incorporates a la... |
| Harmon Whole-Body Motion Generation of Humanoid Robots from Language Descriptions | 2024-10-16 | Humanoid, Robot Control | \n Enumerate and explain the primary technical contributions and insights of the paper. Include both methodological innovations and empirical findings, highlighting what a domain expert would consi... |
| [OKAMI Teaching Humanoid Robots Manipulation Skills through Single Video Imitation](https://ut-austin-rpl.github.io/OKAMI/) | 2024-10-15 | Humanoid, Imitation Learning | The paper introduces OKAMI, a novel framework that leverages object-aware retargeting to allow humanoid robots to imitate actions from single RGB-D video demonstrations. The method includes an inno... |
| [HumanoidBench Simulated Humanoid Benchmark for Whole-Body Locomotion and Manipulation](https://arxiv.org/html/2403.10506v2) | 2024-06-18 | Benchmarks, Humanoid | The primary contributions of the paper include the introduction of HumanoidBench, a high-dimensional benchmark featuring 27 distinct tasks that challenge state-of-the-art reinforcement learning alg... |
| [OmniH2O Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning](https://omni.human2humanoid.com/) | 2024-06-13 | Humanoid, Robot Control | The paper presents the OmniH2O system, which innovatively integrates kinematic pose control with learning from demonstrations and reinforcement learning to facilitate human-to-humanoid teleoperatio... |

## Imitation Learning

*10 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations](https://arxiv.org/html/2507.00990v2) | 2025-07-04 | Imitation Learning, Manipulation, Robot Data | The primary contributions of the paper are the introduction of the RIGVid framework, which allows robots to perform tasks based solely on AI-generated videos, and the empirical validation of this a... |
| [CUPID - Curating Data your Robot Loves with Influence Functions](https://arxiv.org/html/2506.19121v1) | 2025-06-23 | Imitation Learning, Robot Data | The primary contributions of the paper include the introduction of Cupid, a novel data curation method that leverages influence functions to assess the impact of training demonstrations on policy p... |
| [Amplify Actionless Motion Priors for Robot Learning from Videos](https://arxiv.org/html/2506.14198v1) | 2025-06-17 | Imitation Learning | Amplify introduces a decoupled architecture that separates visual motion prediction from action inference, allowing the forward dynamics model to be trained on abundant action-free videos while the... |
| [Object-centric 3D Motion Field for Robot Learning from Human Videos](https://arxiv.org/html/2506.04227v1) | 2025-06-04 | Imitation Learning, Manipulation, Modeling & World Models | The paper makes several key contributions to the field of robot learning from videos. Firstly, it introduces an object-centric 3D motion field as a superior action representation that retains essen... |
| [Dynamic Rank Adjustment in Diffusion Policies for Efficient and Flexible Training](https://arxiv.org/html/2502.03822v3) | 2025-04-26 | Imitation Learning, Manipulation | Key contributions of this paper include the introduction of the DRIFT framework, which employs Singular Value Decomposition (SVD) for dynamic rank adjustment in diffusion policy training. The autho... |
| [NIL - No-data Imitation Learning by Leveraging Pre-trained Video Diffusion Models](https://arxiv.org/html/2503.10626v1) | 2025-03-13 | Diffusion & Flow, Imitation Learning | The primary contributions of the paper include the introduction of No-data Imitation Learning (NIL), which employs pretrained video diffusion models to generate reference videos on-the-fly for trai... |
| [DexMimicGen - Automated Data Generation for Bimanual Dexterous Manipulation via Imitation Learning](https://arxiv.org/html/2410.24185v2) | 2025-03-06 | Imitation Learning, Robot Data | The paper introduces DexMimicGen, a novel automated data generation system that synthesizes trajectories from a limited set of human demonstrations, achieving the generation of 21,000 demonstration... |
| [Reactive Diffusion Policy Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation](https://arxiv.org/html/2503.02881v3) | 2025-03-03 | Diffusion & Flow, Imitation Learning, Manipulation, Tactile | The primary contributions of this work include the development of the TactAR teleoperation system, which facilitates real-time tactile feedback through Augmented Reality, and the Reactive Diffusion... |
| [CLIP-RT Learning Language-Conditioned Robotic Policies from Natural Language Supervision](https://clip-rt.github.io/) | 2024-11-01 | Imitation Learning, VLM & VLA | The primary contributions include the introduction of the CLIP-RT model, which utilizes a vision-language-action framework to learn from natural language instructions. The paper demonstrates that C... |
| [OKAMI Teaching Humanoid Robots Manipulation Skills through Single Video Imitation](https://ut-austin-rpl.github.io/OKAMI/) | 2024-10-15 | Humanoid, Imitation Learning | The paper introduces OKAMI, a novel framework that leverages object-aware retargeting to allow humanoid robots to imitate actions from single RGB-D video demonstrations. The method includes an inno... |

## Manipulation

*37 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [Latent Policy Steering with Embodiment-Agnostic Pretrained World Models](https://arxiv.org/html/2507.13340v1) | 2025-07-17 | Manipulation, Modeling & World Models | The paper introduces two primary contributions: (1) the use of optic flow as an embodiment-agnostic action representation to train a World Model (WM) across varied datasets, which allows for effect... |
| [DreamGrasp - Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation](https://arxiv.org/html/2507.05627v1) | 2025-07-08 | Manipulation, Robot Data | This paper introduces DreamGrasp, a novel framework that integrates large-scale pre-trained image generative models to predict unseen parts of a scene from partial-view images. Key contributions in... |
| [Human2LocoMan Learning Versatile Quadrupedal Manipulation with Human Pretraining](https://arxiv.org/html/2506.16475v2) | 2025-07-07 | Manipulation, Robot Dog | The paper presents several key contributions: it introduces the Human2LocoMan framework, which enables flexible and scalable collection of human demonstrations and robot trajectories for quadrupeda... |
| [AC-DiT Adaptive Coordination Diffusion Transformer for Mobile Manipulation](https://arxiv.org/html/2507.01961v3) | 2025-07-05 | Manipulation | The paper presents the Adaptive Coordination Diffusion Transformer (AC-DiT) as a novel framework that introduces two main contributions: 1. **Mobility-to-Body Conditioning Mechanism**: This mechani... |
| [Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations](https://arxiv.org/html/2507.00990v2) | 2025-07-04 | Imitation Learning, Manipulation, Robot Data | The primary contributions of the paper are the introduction of the RIGVid framework, which allows robots to perform tasks based solely on AI-generated videos, and the empirical validation of this a... |
| [DexWrist A Robotic Wrist for Constrained and Dynamic Manipulation](https://arxiv.org/html/2507.01008v1) | 2025-07-01 | Manipulation, Robotics Platforms | The paper presents the DexWrist as a compliant robotic wrist that utilizes decoupled parallel actuation to enhance manipulation capabilities in constrained environments. Key contributions include a... |
| [RoboEval - Where Robotic Manipulation Meets Structured and Scalable Evaluation](https://arxiv.org/abs/2507.00435) | 2025-07-01 | Benchmarks, Manipulation | The paper introduces RoboEval, a structured evaluation framework that decomposes bimanual manipulation tasks into skill-specific stages, enhancing the diagnostic capabilities of evaluation metrics.... |
| [Scaffolding Dexterous Manipulation with Vision-Language Models](https://arxiv.org/html/2506.19212v1) | 2025-06-24 | Manipulation, Modeling & World Models, VLM & VLA | The key contributions of this paper include the introduction of a novel framework that integrates vision-language models (VLMs) for generating coarse motion plans or "scaffolds" for dexterous manip... |
| [RoboArena Distributed Real-World Evaluation of Generalist Robot Policies](https://arxiv.org/html/2506.18123v1) | 2025-06-22 | Benchmarks, Manipulation | The paper introduces RoboArena, a novel decentralized framework that allows for crowd-sourced evaluations of generalist robot policies. Key contributions include the implementation of a pairwise co... |
| [ViTacFormer - Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation](https://roboverseorg.github.io/ViTacFormerPage/) | 2025-06-19 | Manipulation, Tactile, VLM & VLA |  |
| [SafeMimic Towards Safe and Autonomous Human-to-Robot Imitation for Mobile Manipulation](https://arxiv.org/html/2506.15847v1) | 2025-06-18 | Manipulation, Safety and Robustness | The primary contributions of this paper include the introduction of the SafeMimic framework, which integrates a novel approach to segmenting and interpreting human actions from video, the developme... |
| [Vision in Action Learning Active Perception from Human Demonstrations](https://arxiv.org/html/2506.15666v1) | 2025-06-18 | Manipulation | The paper introduces Vision in Action (ViA), a novel active perception system that utilizes a 6-DoF robotic neck for flexible head movements, allowing for human-like gaze control. Key contributions... |
| [Object-centric 3D Motion Field for Robot Learning from Human Videos](https://arxiv.org/html/2506.04227v1) | 2025-06-04 | Imitation Learning, Manipulation, Modeling & World Models | The paper makes several key contributions to the field of robot learning from videos. Firstly, it introduces an object-centric 3D motion field as a superior action representation that retains essen... |
| [HoMeR - Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control](https://arxiv.org/html/2506.01185v1) | 2025-06-01 | Manipulation, Robotics Platforms | The primary contributions of the paper include the development of a hybrid imitation learning agent that effectively combines keypose and dense action representations for mobile robots. Key insight... |
| [Knowledge Insulating Vision-Language-Action Models Train Fast, Run Fast, Generalize Better](https://arxiv.org/html/2505.23705v1) | 2025-05-29 | Manipulation | The paper introduces a novel training recipe termed \\"knowledge insulation,\\" which allows the VLA model to fine-tune a pre-trained VLM backbone using discrete action tokens while simultaneously ... |
| [Dex1B Learning with 1B Demonstrations for Dexterous Manipulation](https://arxiv.org/html/2506.17198v1) | 2025-05-20 | Datasets, Manipulation | The paper introduces Dex1B, a groundbreaking dataset comprising one billion high-quality demonstrations for dexterous manipulation tasks. Key contributions include a novel generative model that int... |
| ArticuBot Learning Universal Articulated Object Manipulation Policy via Large Scale Simulation | 2025-05-01 | Diffusion & Flow, Manipulation, Sim-to-Real & Real-to-Sim | The primary contributions of this paper include the introduction of ArticuBot, a system that leverages a single learned policy to open diverse categories of articulated objects. The authors propose... |
| [You Only Teach Once Learn One-Shot Bimanual Robotic Manipulation from Video Demonstrations](https://arxiv.org/html/2501.14208v2) | 2025-04-27 | Diffusion & Flow, Manipulation | The primary contributions of the paper are threefold: firstly, the introduction of a method for extracting and injecting dual-arm movements from single-shot human demonstrations, facilitating rapid... |
| [Dynamic Rank Adjustment in Diffusion Policies for Efficient and Flexible Training](https://arxiv.org/html/2502.03822v3) | 2025-04-26 | Imitation Learning, Manipulation | Key contributions of this paper include the introduction of the DRIFT framework, which employs Singular Value Decomposition (SVD) for dynamic rank adjustment in diffusion policy training. The autho... |
| [RUKA Rethinking the Design of Humanoid Hands with Learning](https://ruka-hand.github.io/) | 2025-04-17 | Manipulation, Robotics Platforms | The primary contributions of this work include the design of RUKA, a novel tendon-driven humanoid hand that is both compact and affordable, utilizing 3D-printed components and off-the-shelf parts. ... |
| [Sim-and-Real Co-Training A Simple Recipe for Vision-Based Robotic Manipulation](https://arxiv.org/html/2503.24361v2) | 2025-04-02 | Manipulation, Sim-to-Real & Real-to-Sim | The primary contributions of the paper include the introduction of a systematic co-training strategy that combines real-world and simulation datasets, which has demonstrated a significant average p... |
| [AutoEval Autonomous Evaluation of Generalist Robot Manipulation Policies in the Real World](https://arxiv.org/html/2503.24278v2) | 2025-03-31 | Benchmarks, Manipulation | The primary contribution of the paper is the introduction of AutoEval, a system designed for autonomous evaluation of robot policies that minimizes human intervention. AutoEval enables continuous e... |
| [Can We Detect Failures Without Failure Data Uncertainty-Aware Runtime Failure Detection for Imitation Learning Policies](https://arxiv.org/html/2503.08558v3) | 2025-03-11 | Manipulation, Safety and Robustness | The paper presents FAIL-Detect, a novel two-stage framework for detecting failures in imitation learning-based robotic systems without the need for failure data. The key contributions include the i... |
| [GRIP - A General Robotic Incremental Potential Contact Simulation Dataset for Unified Deformable-Rigid Coupled Grasping](https://arxiv.org/html/2503.05020v2) | 2025-03-06 | Datasets, Manipulation, Robot Data | The primary contributions of this paper include the introduction of the GRIP dataset, which encompasses 1,200 objects and 100,000 grasp poses, facilitating research in both soft and rigid grasping.... |
| [Curating Demonstrations using Online Experience](https://arxiv.org/html/2503.03707v1) | 2025-03-05 | Manipulation, Robot Data | The paper makes significant contributions by introducing Demo-SCORE, a novel approach that automates the curation process through self-assessment based on policy rollout success. Key insights inclu... |
| [Reactive Diffusion Policy Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation](https://arxiv.org/html/2503.02881v3) | 2025-03-03 | Diffusion & Flow, Imitation Learning, Manipulation, Tactile | The primary contributions of this work include the development of the TactAR teleoperation system, which facilitates real-time tactile feedback through Augmented Reality, and the Reactive Diffusion... |
| [Hi Robot Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models](https://arxiv.org/html/2502.19417v1) | 2025-02-26 | Manipulation, VLM & VLA | The primary contributions of this paper include the introduction of a hierarchical vision-language-action (VLA) model that allows robots to process complex prompts and incorporate user feedback eff... |
| [Manual2Skill Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models](https://arxiv.org/html/2502.10090v2) | 2025-02-17 | Manipulation | The primary contributions of the paper include the introduction of Manual2Skill, a framework that utilizes Vision-Language Models (VLMs) to extract structured information from visual manuals, gener... |
| [CordViP Correspondence-based Visuomotor Policy for Dexterous Manipulation in Real-World](https://arxiv.org/html/2502.08449v2) | 2025-02-16 | Manipulation | The paper introduces CordViP, a novel framework that enhances robotic manipulation through correspondence-based visuomotor policies. Key contributions include the development of interaction-aware p... |
| [DOGlove Dexterous Manipulation with a Low-Cost Open-Source Haptic Force Feedback Glove](https://arxiv.org/html/2502.07730v1) | 2025-02-11 | Manipulation, Robotics Platforms | The primary contributions of the paper are the introduction of DOGlove, a low-cost, open-source haptic force feedback glove that can be assembled for under $600. Key innovations include a customize... |
| [DexterityGen Foundation Controller for Unprecedented Dexterity](https://arxiv.org/html/2502.04307v1) | 2025-02-06 | Manipulation | The paper introduces DexterityGen (DexGen), which innovatively combines RL to pretrain large-scale dexterous motion primitives with human teleoperation as a high-level input, effectively creating a... |
| [Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning](https://arxiv.org/html/2410.21845v3) | 2024-10-29 | Manipulation, RL | This paper introduces a novel RL system named Human-in-the-Loop Sample-Efficient Robotic Reinforcement Learning (HIL-SERL), which integrates human feedback through demonstrations and corrections to... |
| [FMB - a Functional Manipulation Benchmark for Generalizable Robotic Learning](https://arxiv.org/html/2401.08553v3) | 2024-09-03 | Benchmarks, Manipulation | The primary contributions of the paper include the introduction of the Functional Manipulation Benchmark (FMB), which consists of a diverse set of 3D-printed objects designed for practical replicat... |
| [DROID - A Large-Scale In-The-Wild Robot Manipulation Dataset](https://arxiv.org/html/2403.12945v2) | 2024-03-19 | Benchmarks, Datasets, Manipulation | The primary contributions of the paper include the introduction of DROID (Distributed Robot Interaction Dataset), which contains 76,000 demonstration trajectories across 564 scenes and 86 tasks. Th... |
| [Yell At Your Robot - Improving On-the-Fly from Language Corrections](https://arxiv.org/html/2403.12910v1) | 2024-03-19 | Manipulation, VLM & VLA | The primary contributions of the paper include the development of the Yell At Your Robot (YAY Robot) system, which integrates human language feedback to continuously improve robot performance in re... |
| [LEAP Hand Dexterous, Low-cost Hybrid Rigid-Soft Hand for Robot Learning](https://v2-adv.leaphand.com/#) | 2023-06-01 | Manipulation, Robotics Platforms | The primary contribution is the LEAP Hand V2, a hybrid rigid-soft robotic hand designed for dexterous manipulation. It utilizes a 3D-printed soft exterior and a rigid internal bone structure to ach... |
| [Learning Fine-Grained Bimanual Manipulation with Low-Cost Hardware](https://arxiv.org/abs/2304.13705) | 2023-04-23 | Manipulation | The paper's primary contributions include the development of ALOHA, a low-cost bimanual teleoperation system that enables fine manipulation, and a novel imitation learning algorithm termed Action C... |

## Modeling & World Models

*18 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [Latent Policy Steering with Embodiment-Agnostic Pretrained World Models](https://arxiv.org/html/2507.13340v1) | 2025-07-17 | Manipulation, Modeling & World Models | The paper introduces two primary contributions: (1) the use of optic flow as an embodiment-agnostic action representation to train a World Model (WM) across varied datasets, which allows for effect... |
| [EmbodieDreamer - Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling](https://arxiv.org/html/2507.05198v1) | 2025-07-07 | Modeling & World Models, Sim-to-Real & Real-to-Sim | The primary contributions of the paper include the introduction of the EmbodieDreamer framework, which consists of two pivotal components: PhysAligner and VisAligner. PhysAligner is a differentiabl... |
| [Playing with Transformer at 30+ FPS via Next-Frame Diffusion](https://arxiv.org/html/2506.01380v2) | 2025-07-04 | Modeling & World Models | The primary contributions of the paper include the introduction of the Next-Frame Diffusion (NFD) framework, which employs block-wise causal attention to enable efficient parallel token generation ... |
| [Geometry-aware 4D Video Generation for Robot Manipulation](https://arxiv.org/html/2507.01099v1) | 2025-07-01 | Modeling & World Models, VLM & VLA | This work introduces a novel 4D video generation framework that integrates temporal modeling with robust 3D geometric consistency by enforcing cross-view pointmap alignment. Key contributions inclu... |
| [WorldVLA Towards Autoregressive Action World Model](https://arxiv.org/html/2506.21539v1) | 2025-06-26 | Modeling & World Models, VLM & VLA | The primary contributions of the paper include the introduction of WorldVLA, which integrates the strengths of VLA and world models into a single framework. The authors propose a novel attention ma... |
| [Scaffolding Dexterous Manipulation with Vision-Language Models](https://arxiv.org/html/2506.19212v1) | 2025-06-24 | Manipulation, Modeling & World Models, VLM & VLA | The key contributions of this paper include the introduction of a novel framework that integrates vision-language models (VLMs) for generating coarse motion plans or "scaffolds" for dexterous manip... |
| [Unified Vision-Language-Action Model](https://arxiv.org/html/2506.19850v1) | 2025-06-24 | Modeling & World Models, VLM & VLA | The main contributions of the paper include the introduction of UniVLA, a novel unified vision-language-action model that encodes vision, language, and action as discrete tokens within a shared voc... |
| [Object-centric 3D Motion Field for Robot Learning from Human Videos](https://arxiv.org/html/2506.04227v1) | 2025-06-04 | Imitation Learning, Manipulation, Modeling & World Models | The paper makes several key contributions to the field of robot learning from videos. Firstly, it introduces an object-centric 3D motion field as a superior action representation that retains essen... |
| [Evaluating Robot Policies in a World Model](https://arxiv.org/html/2506.00613v1) | 2025-05-31 | Modeling & World Models, RL | The paper introduces a novel framework known as World-model-based Policy Evaluation (WPE), which employs a single world model capable of generating action-conditioned video simulations for policy e... |
| [Unified World Models Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets](https://arxiv.org/html/2504.02792v3) | 2025-05-23 | Modeling & World Models, VLM & VLA | The paper introduces Unified World Models (UWM), a framework that integrates action and video diffusion processes within a unified transformer architecture, enabling the effective pretraining of po... |
| [FLARE - Robot Learning with Implicit World Modeling](https://research.nvidia.com/labs/gear/flare/) | 2025-05-22 | Modeling & World Models, VLM & VLA | The paper introduces FLARE (Future Latent Representation Alignment), a novel approach that simplifies the world modeling process by teaching robots to predict compact embeddings of future states ra... |
| [FlowDreamer - A RGB-D World Model with Flow-based Motion Representations for Robot Manipulation](https://arxiv.org/html/2505.10075v1) | 2025-05-15 | Modeling & World Models | The paper introduces FlowDreamer, a two-stage RGB-D world model that explicitly models dynamics prediction and visual rendering separately, leveraging 3D scene flow as a novel motion representation... |
| [AdaWorld Learning Adaptable World Models with Latent Actions](https://arxiv.org/html/2503.18938v3) | 2025-05-14 | Modeling & World Models | AdaWorld contributes significantly to the field by introducing an autoregressive world model that integrates latent actions extracted from videos in a self-supervised manner. This innovative design... |
| [Diffusion-VLA Generalizable and Interpretable Robot Foundation Model via Self-Generated Reasoning](https://arxiv.org/html/2412.03293v2) | 2025-05-13 | Modeling & World Models, VLM & VLA | The primary contributions include the introduction of the DiffusionVLA (DiVLA) framework, which combines autoregressive reasoning and diffusion models, and a reasoning injection module that embeds ... |
| [Occupancy World Model for Robots](https://arxiv.org/html/2505.05512v1) | 2025-05-07 | Modeling & World Models | The paper introduces RoboOccWorld, a novel occupancy world model that integrates Conditional Causal State Attention (CCSA) and Hybrid Spatio-Temporal Aggregation (HSTA) to enhance the prediction of... |
| [UP-VLA A Unified Understanding and Prediction Model for Embodied Agent](https://arxiv.org/html/2501.18867v3) | 2025-01-31 | Modeling & World Models | The paper introduces UP-VLA, a Unified VLA model that integrates both multi-modal understanding and future prediction objectives. This dual approach allows for enhanced comprehension of high-level ... |
| [Cosmos World Foundation Model Platform for Physical AI](https://arxiv.org/html/2501.03575v3) | 2025-01-07 | Modeling & World Models | The paper introduces the Cosmos World Foundation Model Platform, which offers a comprehensive solution for generating customized world models tailored to specific Physical AI applications. Key cont... |
| [Understanding World or Predicting Future A Comprehensive Survey of World Models](https://arxiv.org/html/2411.14499v2) | 2024-11-21 | Modeling & World Models, Survey | The paper contributes a novel categorization framework for world models that emphasizes both implicit representations for understanding and predictive models for forecasting future states. The auth... |

## RL

*32 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [Reinforcement Learning with Action Chunking](https://arxiv.org/html/2507.07969v2) | 2025-07-15 | RL | The paper introduces Q-chunking, a novel RL methodology that employs action chunking to enhance exploration and sample efficiency. Key contributions include the formulation of RL in a temporally ex... |
| [Reinforcement Learning with Action Chunking 1](https://arxiv.org/html/2507.07969v2) | 2025-07-15 | RL | The primary contributions of the paper include the introduction of a novel method termed Q-chunking, which incorporates action chunking into traditional Q-learning frameworks. This approach facilit... |
| [EXPO Stable Reinforcement Learning with Expressive Policies](https://arxiv.org/html/2507.07986v2) | 2025-07-15 | RL | The key contributions of the paper include the development of a novel algorithm named EXpressive Policy Optimization (EXPO), which facilitates stable value maximization by constructing an on-the-fl... |
| [Efficient Online Reinforcement Learning Fine-Tuning Need Not Retain Offline Data](https://arxiv.org/html/2412.07762v3) | 2025-07-02 | RL | The paper introduces Warm-start Reinforcement Learning (WSRL), a novel approach that allows for effective online fine-tuning without retaining offline data. Key contributions include the identifica... |
| [Steering Your Diffusion Policy with Latent Space Reinforcement Learning](https://arxiv.org/html/2506.15799v1) | 2025-06-18 | Diffusion & Flow, RL | The primary contribution of the paper is the introduction of diffusion steering via reinforcement learning (Dsrl), a novel approach that facilitates fast autonomous adaptation of BC-trained policie... |
| [GMT General Motion Tracking for Humanoid Whole-Body Control](https://arxiv.org/html/2506.14770v1) | 2025-06-17 | Humanoid, RL | The primary contributions of this work include the introduction of the Adaptive Sampling strategy, which optimally balances the training of easier and more challenging motions, and a Motion Mixture... |
| [Monte Carlo Tree Diffusion for System 2 Planning](https://arxiv.org/html/2502.07202v4) | 2025-06-11 | RL, Search and Planning | The primary contributions of the paper include the introduction of the Monte Carlo Tree Diffusion (MCTD) framework, which integrates the generative strengths of diffusion models with the adaptive s... |
| [Reinforcement Learning via Implicit Imitation Guidance](https://arxiv.org/html/2506.07505v1) | 2025-06-09 | RL | The primary contribution of the paper is the introduction of the Data-Guided Noise (DGN) framework, which innovatively uses prior data to guide exploration by injecting noise into the policy, shape... |
| [SLAC Simulation-Pretrained Latent Action Space for Whole-Body Real-World RL](https://arxiv.org/html/2506.04147v2) | 2025-06-07 | Humanoid, RL | The primary contributions of the paper include the introduction of SLAC (Simulation-Pretrained Latent Action Space), a framework that allows for the pretraining of a latent action space in low-fide... |
| [One Policy but Many Worlds - A Scalable Unified Policy for Versatile Humanoid Locomotion](https://arxiv.org/html/2505.18780v2) | 2025-06-03 | Humanoid, RL | The primary contribution of this work is the introduction of DreamPolicy, a unified framework that integrates offline data and employs a terrain-aware autoregressive diffusion planner to synthesize... |
| [Evaluating Robot Policies in a World Model](https://arxiv.org/html/2506.00613v1) | 2025-05-31 | Modeling & World Models, RL | The paper introduces a novel framework known as World-model-based Policy Evaluation (WPE), which employs a single world model capable of generating action-conditioned video simulations for policy e... |
| [Diffusion Guidance Is a Controllable Policy Improvement Operator](https://arxiv.org/html/2505.23458v1) | 2025-05-29 | Diffusion & Flow, RL | This paper presents the CFGRL framework, which innovatively connects diffusion model guidance with RL policy improvement. Notable contributions include a novel method for policy extraction that all... |
| FastTD3 Simple, Fast, and Capable Reinforcement Learning for Humanoid Control | 2025-05-29 | Humanoid, RL | The paper introduces FastTD3, a novel RL algorithm designed for increased efficiency in training humanoid robots. It incorporates parallel simulation, large-batch updates, and a distributional crit... |
| [FLEX A Backbone for Diffusion-Based Modeling of Spatio-temporal Physical Systems](https://arxiv.org/html/2505.17351v1) | 2025-05-23 | Diffusion & Flow, RL | The paper introduces FLEX (FLow EXpert), a novel backbone architecture that combines U-Net and Transformer elements to enhance both local detail and global dependency representation. Key contributi... |
| [Strengthening Generative Robot Policies through Predictive World Modeling](https://arxiv.org/html/2502.00622v2) | 2025-05-22 | RL | GPC integrates generative modeling and predictive world modeling, allowing robots to learn from both expert demonstrations and random exploratory behavior to enhance control policies. The framework... |
| [Conditioning Matters Training Diffusion Policies is Faster Than You Think](https://arxiv.org/html/2505.11123v1) | 2025-05-16 | Diffusion & Flow, RL | The primary contribution of this paper is the introduction of Cocos, a novel conditional flow matching approach that modifies the source distribution to be condition-dependent. This method enhances... |
| [Video Prediction Policy - A Generalist Robot Policy with Predictive Visual Representations](https://arxiv.org/html/2412.14803) | 2025-05-04 | Diffusion & Flow, RL | The primary contributions of the paper include the introduction of the Video Prediction Policy (VPP), which learns implicit inverse dynamics conditioned on future visual representations. The author... |
| [ASAP Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills](https://arxiv.org/html/2502.01143v3) | 2025-04-26 | RL, Simulation | The primary contributions of this work include the introduction of the ASAP framework, which encompasses a two-stage approach for aligning simulation and real-world dynamics. The methodology innova... |
| [Learning Humanoid Standing-up Control across Diverse Postures](https://arxiv.org/html/2502.08378v2) | 2025-04-19 | Humanoid, RL, Robot Control | The paper presents the HoST framework, a reinforcement learning-based solution that learns standing-up control from scratch, enabling posture-adaptive motions without predefined trajectories. Key c... |
| [ConRFT A Reinforced Fine-tuning Method for VLA Models via Consistency Policy](https://arxiv.org/html/2502.05450v2) | 2025-04-14 | Finetuning, RL, VLM & VLA | The paper introduces a novel reinforced fine-tuning approach named ConRFT, which integrates both offline and online fine-tuning stages using a unified consistency-based training objective. Key cont... |
| [Fast Adaptation with Behavioral Foundation Models](https://arxiv.org/html/2504.07896v1) | 2025-04-10 | LBM, RL | The paper introduces two novel fast adaptation strategies: Residual Latent Adaptation (ReLA) and Lookahead Latent Adaptation (LoLA). ReLA utilizes a residual critic to address reward projection err... |
| [Echo Chamber RL Post-training Amplifies Behaviors Learned in Pretraining](https://arxiv.org/html/2504.07912v1) | 2025-04-10 | Finetuning, RL | The paper presents a systematic end-to-end study of RL fine-tuning on models trained from scratch using various mixtures of fully open datasets. Key contributions include demonstrating that RL cons... |
| [GTR Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training](https://arxiv.org/html/2503.08525v1) | 2025-03-11 | RL | The primary contributions of the paper include the introduction of ==Guided Thought Reinforcement (GTR), a novel framework== that integrates automated process guidance to enhance the reasoning abil... |
| [DextrAH-RGB Visuomotor Policies to Grasp Anything with Dexterous Hands](https://arxiv.org/html/2412.01791v2) | 2025-02-01 | RL | The primary contributions of the paper include the introduction of DextrAH-RGB, a novel approach that trains a fabric-guided policy (FGP) in simulation exclusively from RGB inputs, enabling robust ... |
| [RLZero - Direct Policy Inference from Language Without In-Domain Supervision](https://arxiv.org/html/2412.05718v2) | 2024-12-07 | RL | The paper presents a novel framework, RLZero, which comprises three main components: imagine, project, and imitate. The primary contributions include the introduction of a zero-shot policy inferenc... |
| [Basis-to-Basis Operator Learning Using Function Encoders](https://arxiv.org/html/2410.00171v2) | 2024-11-12 | RL | The primary contributions of the paper include the development of the B2B framework which efficiently learns both basis functions for input and output spaces and a mapping between their coefficient... |
| [Precise and Dexterous Robotic Manipulation via Human-in-the-Loop Reinforcement Learning](https://arxiv.org/html/2410.21845v3) | 2024-10-29 | Manipulation, RL | This paper introduces a novel RL system named Human-in-the-Loop Sample-Efficient Robotic Reinforcement Learning (HIL-SERL), which integrates human feedback through demonstrations and corrections to... |
| [Automated Creation of Digital Cousins for Robust Policy Learning](https://arxiv.org/html/2410.07408v3) | 2024-10-19 | RL | The paper introduces the Automated Creation of Digital Cousins (ACDC), a fully automated pipeline that generates interactive virtual environments from single RGB images without human input. It show... |
| [SAPG - Split and Aggregate Policy Gradients](https://arxiv.org/html/2407.20230v1) | 2024-07-29 | RL | This paper's primary contributions include the development of the Split and Aggregate Policy Gradients (SAPG) algorithm, which innovatively splits environments into chunks that are optimized by sep... |
| [Diffusion Policy Visuomotor Policy Learning via Action Diffusion](https://arxiv.org/html/2303.04137v5) | 2024-03-14 | Diffusion & Flow, RL | The authors introduce the Diffusion Policy framework, which formulates robot behaviors as a conditional denoising diffusion process. Key contributions include the integration of receding-horizon co... |
| [RLPD - Efficient Online Reinforcement Learning with Offline Data](https://pdf2md.morethan.io/) | 2023-02-06 | RL | The primary contributions of the paper include the introduction of RLPD (Reinforcement Learning with Prior Data), a method that extends off-policy RL techniques to effectively utilize offline datas... |
| The Surprising Effectiveness of Negative Reinforcement in LLM Reasoning | Unknown | LLM, RL | The primary contributions of this paper include the decomposition of the RLVR objective into Positive Sample Reinforcement (PSR) and Negative Sample Reinforcement (NSR), which allows for a clearer ... |

## Robot Control

*19 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [LeVERB Humanoid Whole-Body Control with Latent Vision-Language Instruction](https://arxiv.org/html/2506.13751v2) | 2025-06-19 | Humanoid, Robot Control | The paper introduces LeVERB, a hierarchical framework that allows for latent instruction-following in humanoid WBC. Key contributions include a novel dual-process architecture that separates high-l... |
| [From Experts to a Generalist Toward General Whole-Body Control for Humanoid Robots](https://arxiv.org/html/2506.12779v2) | 2025-06-19 | Humanoid, Robot Control | The paper introduces the BumbleBee (BB) framework, which combines motion clustering with sim-to-real adaptation to create a generalist controller that maintains agility and robustness across variou... |
| [Prompting with the Future Open-World Model Predictive Control with Interactive Digital Twins](https://arxiv.org/html/2506.13761v1) | 2025-06-16 | Robot Control, Search and Planning, Simulation | The paper introduces the Prompting with the Future (PWTF) framework, which integrates VLMs with interactive digital twins to enhance robotic manipulation. A key contribution is the construction of ... |
| [KungfuBot - Physics-Based Humanoid Whole-Body Control for Learning Highly-Dynamic Skills](https://kungfu-bot.github.io/) | 2025-06-15 | Humanoid, Robot Control | The primary contributions include a novel physics-based humanoid control framework that integrates multi-step motion processing with adaptive motion tracking. Methodologically, the authors propose ... |
| [Rodrigues Network for Learning Robot Actions](https://arxiv.org/html/2506.02618v1) | 2025-06-03 | Robot Control | The primary contributions of the paper include the introduction of the Neural Rodrigues Operator, a learnable generalization of classical forward kinematics that embeds kinematic awareness into neu... |
| [Diffusion Model Predictive Control](https://arxiv.org/html/2410.05364v2) | 2025-05-22 | Diffusion & Flow, Robot Control | The primary contributions of the paper include the development of D-MPC, which utilizes multi-step action proposals and dynamics learned through diffusion models to enhance performance in offline p... |
| [HWC-Loco A Hierarchical Whole-Body Control Approach to Robust Humanoid Locomotion](https://arxiv.org/html/2503.00923v3) | 2025-05-18 | Robot Control | The primary contributions of the paper include the introduction of the HWC-Loco algorithm, which reformulates policy learning as a robust optimization problem that prioritizes safety while maintain... |
| [HuB Learning Extreme Humanoid Balance](https://arxiv.org/html/2505.07294v1) | 2025-05-12 | Humanoid, Robot Control | The primary contributions of the paper include the introduction of the HuB framework, which integrates reference motion refinement, balance-aware policy learning, and sim-to-real robustness trainin... |
| [AMO Adaptive Motion Optimization for Hyper-Dexterous Humanoid Whole-Body Control](https://arxiv.org/html/2505.03738v1) | 2025-05-06 | Humanoid, Robot Control | The paper introduces Adaptive Motion Optimization (AMO), which integrates sim-to-real reinforcement learning (RL) with trajectory optimization. Key contributions include a hybrid motion synthesis a... |
| [LangWBC Language-directed Humanoid Whole-Body Control via End-to-end Learning](https://arxiv.org/html/2504.21738v1) | 2025-04-30 | Humanoid, Robot Control | The paper presents a novel end-to-end framework called LangWBC, which directly maps natural language commands to physical actions. A significant contribution is the use of a Conditional Variational... |
| [Learning Getting-Up Policies for Real-World Humanoid Robots](https://arxiv.org/html/2502.12152v2) | 2025-04-27 | Humanoid, Robot Control | The paper presents several key contributions, including the development of a novel two-stage reinforcement learning framework named HumanUP, which effectively learns getting-up policies from divers... |
| [Learning Humanoid Standing-up Control across Diverse Postures](https://arxiv.org/html/2502.08378v2) | 2025-04-19 | Humanoid, RL, Robot Control | The paper presents the HoST framework, a reinforcement learning-based solution that learns standing-up control from scratch, enabling posture-adaptive motions without predefined trajectories. Key c... |
| [A Unified and General Humanoid Whole-Body Controller for Versatile Locomotion](https://arxiv.org/html/2502.03206v3) | 2025-04-12 | Humanoid, Robot Control | The primary contributions of the paper are the introduction of HugWBC, a unified whole-body controller that supports various locomotion behaviors with a single policy. The method employs a general ... |
| [HOVER Versatile Neural Whole-Body Controller for Humanoid Robots](https://arxiv.org/html/2410.21229v2) | 2025-03-06 | Humanoid, Robot Control | The primary contributions include the introduction of HOVER, a multi-mode policy distillation framework that consolidates diverse control modes into a single policy, enabling efficient transitions ... |
| [InterMimic Towards Universal Whole-Body Control for Physics-Based Human-Object Interactions](https://arxiv.org/html/2502.20390v1) | 2025-02-27 | Humanoid, Robot Control | The primary contributions of the paper include the introduction of the InterMimic framework, which integrates a teacher-student policy distillation approach to improve motion imitation from imperfe... |
| [HOMIE Humanoid Loco-Manipulation with Isomorphic Exoskeleton Cockpit](https://arxiv.org/html/2502.13013v2) | 2025-02-18 | Humanoid, Robot Control | The primary contributions of the paper include the introduction of HOMIE, a semi-autonomous teleoperation system that integrates a reinforcement learning (RL) policy designed for body control mappe... |
| Harmon Whole-Body Motion Generation of Humanoid Robots from Language Descriptions | 2024-10-16 | Humanoid, Robot Control | \n Enumerate and explain the primary technical contributions and insights of the paper. Include both methodological innovations and empirical findings, highlighting what a domain expert would consi... |
| [Full-Order Sampling-Based MPC for Torque-Level Locomotion Control via Diffusion-Style Annealing](https://arxiv.org/html/2409.15610v1) | 2024-09-23 | Diffusion & Flow, Robot Control | The primary contributions of the paper include the introduction of DIAL-MPC (Diffusion-Inspired Annealing for Legged MPC), a novel sampling-based MPC framework that incorporates a diffusion-style a... |
| [OmniH2O Universal and Dexterous Human-to-Humanoid Whole-Body Teleoperation and Learning](https://omni.human2humanoid.com/) | 2024-06-13 | Humanoid, Robot Control | The paper presents the OmniH2O system, which innovatively integrates kinematic pose control with learning from demonstrations and reinforcement learning to facilitate human-to-humanoid teleoperatio... |

## Robot Data

*12 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [Is Diversity All You Need for Scalable Robotic Manipulation](https://arxiv.org/html/2507.06219v1) | 2025-07-08 | Cross-Embodiment, Robot Data | The paper presents three main contributions: (1) It establishes that task diversity is more critical than the sheer number of demonstrations per task for effective transfer to new scenarios, sugges... |
| [DreamGrasp - Zero-Shot 3D Multi-Object Reconstruction from Partial-View Images for Robotic Manipulation](https://arxiv.org/html/2507.05627v1) | 2025-07-08 | Manipulation, Robot Data | This paper introduces DreamGrasp, a novel framework that integrates large-scale pre-trained image generative models to predict unseen parts of a scene from partial-view images. Key contributions in... |
| [Robotic Manipulation by Imitating Generated Videos Without Physical Demonstrations](https://arxiv.org/html/2507.00990v2) | 2025-07-04 | Imitation Learning, Manipulation, Robot Data | The primary contributions of the paper are the introduction of the RIGVid framework, which allows robots to perform tasks based solely on AI-generated videos, and the empirical validation of this a... |
| [CUPID - Curating Data your Robot Loves with Influence Functions](https://arxiv.org/html/2506.19121v1) | 2025-06-23 | Imitation Learning, Robot Data | The primary contributions of the paper include the introduction of Cupid, a novel data curation method that leverages influence functions to assess the impact of training demonstrations on policy p... |
| [RoboTwin 2.0 - A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation](https://arxiv.org/html/2506.18088v1) | 2025-06-22 | Robot Data, Simulation | The key contributions of the paper include the introduction of RoboTwin 2.0, a scalable simulation framework that employs a multimodal large language model (MLLM) for task-level execution code gene... |
| EgoZero - Robot Learning from Smart Glasses | 2025-05-26 | Robot Data | EgoZero introduces a novel framework for extracting robot-executable actions from spontaneous human demonstrations, significantly reducing the need for robot-specific data. The system innovatively ... |
| [DreamGen Unlocking Generalization in Robot Learning through Neural Trajectories](https://arxiv.org/html/2505.12705v1) | 2025-05-19 | Robot Data, Simulation | The primary contributions of the paper include the introduction of DreamGen, a four-stage pipeline that uses neural trajectories for training robot policies. This approach allows for strong behavio... |
| [Real2Render2Real - Scaling Robot Data Without Dynamics Simulation or Robot Hardware](https://arxiv.org/html/2505.09601v1) | 2025-05-14 | Robot Data, Sim-to-Real & Real-to-Sim | The paper introduces Real2Render2Real (R2R2R), a novel framework that synthesizes robot training data from smartphone-captured object scans and demonstration videos without requiring dynamics simul... |
| [DexMimicGen - Automated Data Generation for Bimanual Dexterous Manipulation via Imitation Learning](https://arxiv.org/html/2410.24185v2) | 2025-03-06 | Imitation Learning, Robot Data | The paper introduces DexMimicGen, a novel automated data generation system that synthesizes trajectories from a limited set of human demonstrations, achieving the generation of 21,000 demonstration... |
| [GRIP - A General Robotic Incremental Potential Contact Simulation Dataset for Unified Deformable-Rigid Coupled Grasping](https://arxiv.org/html/2503.05020v2) | 2025-03-06 | Datasets, Manipulation, Robot Data | The primary contributions of this paper include the introduction of the GRIP dataset, which encompasses 1,200 objects and 100,000 grasp poses, facilitating research in both soft and rigid grasping.... |
| [Curating Demonstrations using Online Experience](https://arxiv.org/html/2503.03707v1) | 2025-03-05 | Manipulation, Robot Data | The paper makes significant contributions by introducing Demo-SCORE, a novel approach that automates the curation process through self-assessment based on policy rollout success. Key insights inclu... |
| [DemoGen Synthetic Demonstration Generation for Data-Efficient Visuomotor Policy Learning](https://arxiv.org/html/2502.16932v1) | 2025-02-24 | Robot Data | The primary contributions of the paper include the introduction of DemoGen, a fully synthetic approach for generating demonstrations that augment spatial generalization capabilities in visuomotor p... |

## Robotics Platforms

*12 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [DexWrist A Robotic Wrist for Constrained and Dynamic Manipulation](https://arxiv.org/html/2507.01008v1) | 2025-07-01 | Manipulation, Robotics Platforms | The paper presents the DexWrist as a compliant robotic wrist that utilizes decoupled parallel actuation to enhance manipulation capabilities in constrained environments. Key contributions include a... |
| [HoMeR - Learning In-the-Wild Mobile Manipulation via Hybrid Imitation and Whole-Body Control](https://arxiv.org/html/2506.01185v1) | 2025-06-01 | Manipulation, Robotics Platforms | The primary contributions of the paper include the development of a hybrid imitation learning agent that effectively combines keypose and dense action representations for mobile robots. Key insight... |
| [Towards Embodiment Scaling Laws in Robot Locomotion](https://arxiv.org/html/2505.05753v1) | 2025-05-09 | Cross-Embodiment, Robotics Platforms | The primary contributions of this paper include the development of a large-scale dataset, GenBot-1K, consisting of approximately 1,000 diverse robot embodiments, and the introduction of a two-stage... |
| [Demonstrating Berkeley Humanoid Lite An Open-source, Accessible, and Customizable 3D-printed Humanoid Robot](https://arxiv.org/html/2504.17249v1) | 2025-04-24 | Humanoid, Robotics Platforms | The primary contributions include the design of Berkeley Humanoid Lite, a mid-scale humanoid robot that utilizes modular 3D-printed components, making it both accessible and customizable. The autho... |
| [RUKA Rethinking the Design of Humanoid Hands with Learning](https://ruka-hand.github.io/) | 2025-04-17 | Manipulation, Robotics Platforms | The primary contributions of this work include the design of RUKA, a novel tendon-driven humanoid hand that is both compact and affordable, utilizing 3D-printed components and off-the-shelf parts. ... |
| Categorizing robots by performance fitness into the tree of robots - Nature Machine Intelligence | 2025-02-21 | Robotics Platforms | The paper's key contributions include the introduction of the 'tree of robots' taxonomy, which categorizes robots based on their fitness to perform physical interaction processes. The authors prese... |
| [DOGlove Dexterous Manipulation with a Low-Cost Open-Source Haptic Force Feedback Glove](https://arxiv.org/html/2502.07730v1) | 2025-02-11 | Manipulation, Robotics Platforms | The primary contributions of the paper are the introduction of DOGlove, a low-cost, open-source haptic force feedback glove that can be assembled for under $600. Key innovations include a customize... |
| [ToddlerBot Open-Source ML-Compatible Humanoid Platform for Loco-Manipulation](https://toddlerbot.github.io/) | 2025-02-05 | Humanoid, Robotics Platforms | ToddlerBot introduces a novel platform characterized by its low-cost, open-source architecture, which allows for high-fidelity digital twin modeling. The platform features a plug-and-play calibrati... |
| TidyBot++ An Open-Source Holonomic Mobile Manipulator for Robot Learning | 2024-12-11 | Robotics Platforms | The paper presents an open-source mobile manipulator, TidyBot++, that features a holonomic design, allowing for independent control of all planar degrees of freedom, thus enhancing maneuverability.... |
| [Universal Manipulation Interface In-The-Wild Robot Teaching Without In-The-Wild Robots](https://arxiv.org/html/2402.10329v3) | 2024-03-06 | Robotics Platforms | The primary contributions include the development of the Universal Manipulation Interface (UMI), which utilizes hand-held grippers and a novel policy interface design that addresses latency and act... |
| [Mobile ALOHA - Learning Bimanual Mobile Manipulation with Low-Cost Whole-Body Teleoperation](https://arxiv.org/html/2401.02117v1) | 2024-01-04 | Robotics Platforms | The paper introduces Mobile ALOHA, a low-cost teleoperation system that combines whole-body control with mobile manipulation capabilities. A key contribution is the finding that co-training with st... |
| [LEAP Hand Dexterous, Low-cost Hybrid Rigid-Soft Hand for Robot Learning](https://v2-adv.leaphand.com/#) | 2023-06-01 | Manipulation, Robotics Platforms | The primary contribution is the LEAP Hand V2, a hybrid rigid-soft robotic hand designed for dexterous manipulation. It utilizes a 3D-printed soft exterior and a rigid internal bone structure to ach... |

## Safety and Robustness

*6 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [SafeMimic Towards Safe and Autonomous Human-to-Robot Imitation for Mobile Manipulation](https://arxiv.org/html/2506.15847v1) | 2025-06-18 | Manipulation, Safety and Robustness | The primary contributions of this paper include the introduction of the SafeMimic framework, which integrates a novel approach to segmenting and interpreting human actions from video, the developme... |
| [SafeVLA Towards Safety Alignment of Vision- Language-Action Model via Constrained Learning](https://arxiv.org/html/2503.03480v2) | 2025-05-31 | Safety and Robustness | The authors introduce an Integrated Safety Approach (ISA), which systematically models safety requirements within a Constrained Markov Decision Process (CMDP) framework, thereby allowing for explic... |
| [BadVLA Towards Backdoor Attacks on Vision-Language-Action Models via Objective-Decoupled Optimization](https://arxiv.org/html/2505.16640v1) | 2025-05-22 | Safety and Robustness | The paper introduces BadVLA, a novel two-phase backdoor attack framework specifically designed for VLA models. It emphasizes the method's ability to achieve nearly 100% attack success rates while m... |
| [When Pre-trained Visual Representations Fall Short Limitations in Visuo-motor Robot Learning](https://arxiv.org/html/2502.03270) | 2025-05-05 | Safety and Robustness, VLM & VLA | The primary contributions of the paper include a novel approach that enhances PVRs by incorporating temporal perception and task completion awareness, which the authors claim leads to significant p... |
| [Can We Detect Failures Without Failure Data Uncertainty-Aware Runtime Failure Detection for Imitation Learning Policies](https://arxiv.org/html/2503.08558v3) | 2025-03-11 | Manipulation, Safety and Robustness | The paper presents FAIL-Detect, a novel two-stage framework for detecting failures in imitation learning-based robotic systems without the need for failure data. The key contributions include the i... |
| [Evaluating and Improving Robustness in Large Language Models A Survey and Future Directions](https://arxiv.org/html/2506.11111v1) | 2024-08-20 | Safety and Robustness | The primary contributions of this paper include a comprehensive taxonomy of LLM robustness, categorizing it into adversarial robustness, OOD robustness, and robustness evaluation. The authors propo... |

## Sim-to-Real & Real-to-Sim

*6 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [EmbodieDreamer - Advancing Real2Sim2Real Transfer for Policy Training via Embodied World Modeling](https://arxiv.org/html/2507.05198v1) | 2025-07-07 | Modeling & World Models, Sim-to-Real & Real-to-Sim | The primary contributions of the paper include the introduction of the EmbodieDreamer framework, which consists of two pivotal components: PhysAligner and VisAligner. PhysAligner is a differentiabl... |
| [Real2Render2Real - Scaling Robot Data Without Dynamics Simulation or Robot Hardware](https://arxiv.org/html/2505.09601v1) | 2025-05-14 | Robot Data, Sim-to-Real & Real-to-Sim | The paper introduces Real2Render2Real (R2R2R), a novel framework that synthesizes robot training data from smartphone-captured object scans and demonstration videos without requiring dynamics simul... |
| [X-Sim Cross-Embodiment Learning via Real-to-Sim-to-Real](https://arxiv.org/html/2505.07096v3) | 2025-05-11 | Cross-Embodiment, Diffusion & Flow, Sim-to-Real & Real-to-Sim | The paper introduces X-Sim, a novel real-to-sim-to-real framework that leverages object motion as a transferable signal for training robot policies in simulation. Key contributions include the deve... |
| ArticuBot Learning Universal Articulated Object Manipulation Policy via Large Scale Simulation | 2025-05-01 | Diffusion & Flow, Manipulation, Sim-to-Real & Real-to-Sim | The primary contributions of this paper include the introduction of ArticuBot, a system that leverages a single learned policy to open diverse categories of articulated objects. The authors propose... |
| [Sim-and-Real Co-Training A Simple Recipe for Vision-Based Robotic Manipulation](https://arxiv.org/html/2503.24361v2) | 2025-04-02 | Manipulation, Sim-to-Real & Real-to-Sim | The primary contributions of the paper include the introduction of a systematic co-training strategy that combines real-world and simulation datasets, which has demonstrated a significant average p... |
| [Scalable Real2Sim Physics-Aware Asset Generation Via Robotic Pick-and-Place Setups](https://arxiv.org/html/2503.00370v2) | 2025-04-01 | Sim-to-Real & Real-to-Sim | This work contributes a comprehensive, automated pipeline that successfully integrates both geometric and physical property identification into a single workflow. Key innovations include a general ... |

## Simulation

*19 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [RoboTwin 2.0 - A Scalable Data Generator and Benchmark with Strong Domain Randomization for Robust Bimanual Robotic Manipulation](https://arxiv.org/html/2506.18088v1) | 2025-06-22 | Robot Data, Simulation | The key contributions of the paper include the introduction of RoboTwin 2.0, a scalable simulation framework that employs a multimodal large language model (MLLM) for task-level execution code gene... |
| [Prompting with the Future Open-World Model Predictive Control with Interactive Digital Twins](https://arxiv.org/html/2506.13761v1) | 2025-06-16 | Robot Control, Search and Planning, Simulation | The paper introduces the Prompting with the Future (PWTF) framework, which integrates VLMs with interactive digital twins to enhance robotic manipulation. A key contribution is the construction of ... |
| [DreamGen Unlocking Generalization in Robot Learning through Neural Trajectories](https://arxiv.org/html/2505.12705v1) | 2025-05-19 | Robot Data, Simulation | The primary contributions of the paper include the introduction of DreamGen, a four-stage pipeline that uses neural trajectories for training robot policies. This approach allows for strong behavio... |
| [SimPRIVE a Simulation framework for Physical Robot Interaction with Virtual Environments](https://arxiv.org/html/2504.21454) | 2025-04-30 | Simulation | The primary contributions of the paper include the development of SimPRIVE, a versatile simulation framework capable of facilitating physical robot interactions within customizable virtual environm... |
| [ASAP Aligning Simulation and Real-World Physics for Learning Agile Humanoid Whole-Body Skills](https://arxiv.org/html/2502.01143v3) | 2025-04-26 | RL, Simulation | The primary contributions of this work include the introduction of the ASAP framework, which encompasses a two-stage approach for aligning simulation and real-world dynamics. The methodology innova... |
| [RoboVerse Towards a Unified Platform, Dataset and Benchmark for Scalable and Generalizable Robot Learning](https://arxiv.org/html/2504.18904v1) | 2025-04-26 | Benchmarks, Datasets, Simulation | The primary contributions of this paper include the introduction of RoboVerse, a comprehensive framework that integrates a simulation platform, a large-scale synthetic dataset, and unified benchmar... |
| [Aerial Gym Simulator A Framework for Highly Parallelized Simulation of Aerial Robots](https://arxiv.org/html/2503.01471v1) | 2025-03-03 | Simulation | The primary contributions include the introduction of the Aerial Gym Simulator, which leverages NVIDIA Isaac Gym to deliver a modular and highly parallelized simulation framework. It offers extensi... |
| [Robot Data Curation with Mutual Information Estimators](https://arxiv.org/html/2502.08623v1) | 2025-02-12 | Simulation | The primary contributions of this work include the introduction of the Demonstration Information Estimation (DemInf) method, which employs k-nearest neighbor (k-NN) estimators for mutual informatio... |
| [MuJoCo Playground](https://arxiv.org/html/2502.08844v1) | 2025-02-12 | Simulation | The primary contributions of the paper include the development of MuJoCo Playground, which integrates a physics engine, batch renderer, and training environments into a seamless framework for robot... |
| [Genesis — A Generative and Universal Physics Engine for Robotics and Beyond](https://genesis-world.readthedocs.io/en/latest/) | 2024-12-10 | Simulation | The paper introduces a novel physics engine that integrates multiple state-of-the-art solvers into a unified architecture, significantly enhancing simulation speed and accuracy. The authors provide... |
| [Demonstrating GPU Parallelized Robot Simulation and Rendering for Generalizable Embodied AI with ManiSkill3](https://arxiv.org/html/2410.00425v2) | 2024-10-01 | Simulation | ManiSkill3 is introduced as a novel robotics simulator that offers state-of-the-art GPU parallelized simulation and rendering capabilities, achieving up to 30,000 FPS while maintaining 2-3x lower G... |
| [Demonstrating GPU Parallelized Robot Simulation and Rendering for Generalizable Embodied AI with ManiSkill3 1](https://arxiv.org/html/2410.00425v2) | 2024-10-01 | Simulation | The primary contributions of this work are the introduction of ManiSkill3, which features an efficient GPU parallelized simulation and rendering framework. Key innovations include the ability to su... |
| [RoboCasa Large-Scale Simulation of Everyday Tasks for Generalist Robots](https://arxiv.org/html/2406.02523v1) | 2024-06-04 | Benchmarks, Simulation | The primary contributions of the paper include the introduction of RoboCasa, which features diverse kitchen scenes, thousands of 3D object assets, and a comprehensive set of 100 tasks that encompas... |
| [DexArt - Benchmarking Generalizable Dexterous Manipulation with Articulated Objects](https://arxiv.org/pdf/2305.05706) | 2023-05-09 | Benchmarks, Simulation | The primary contributions of the paper include the introduction of the DexArt benchmark, specifically designed for evaluating dexterous manipulation of articulated objects. This benchmark comprises... |
| [AI2-THOR - An Interactive 3D Environment for Visual AI](https://arxiv.org/abs/1712.05474) | 2022-08-26 | Benchmarks, Simulation | The primary contributions of the paper include the introduction of AI2-THOR, a framework that allows for the simulation of near photo-realistic 3D environments featuring diverse interactive objects... |
| [CALVIN - A Benchmark for Language-Conditioned Policy Learning for Long-Horizon Robot Manipulation Tasks](https://arxiv.org/abs/2112.03227) | 2022-07-13 | Benchmarks, Simulation | The paper introduces CALVIN, an open-source benchmark designed for learning long-horizon language-conditioned tasks, which enables robots to perform intricate manipulation actions based on natural ... |
| [SAPIEN - Simulator from UCSD](https://sapien.ucsd.edu/) | 2020-03-19 | Simulation | The primary contributions of the paper include the introduction of the SAPIEN simulator, which integrates advanced physics simulations with a user-friendly interface for researchers. The authors de... |
| [RLBench - The Robot Learning Benchmark & Learning Environment](https://pdf2md.morethan.io/) | 2019-09-26 | Benchmarks, Simulation | The paper introduces RLBench, a novel benchmark and learning environment designed for robot learning research. Key contributions include the provision of 100 unique, hand-designed tasks that vary i... |
| [DeepMind Control Suite](https://pdf2md.morethan.io/) | 2018-01-03 | Benchmarks, Simulation | The primary contributions of the paper are the introduction of the DeepMind Control Suite, which includes a wide range of well-defined continuous control tasks, and the establishment of a unified r... |

## Survey

*5 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [Vision Language Action Models in Robotic Manipulation A Systematic Review](https://arxiv.org/html/2507.10672v1) | 2025-07-14 | Survey, VLM & VLA | The paper presents several key contributions: 1) A comprehensive analysis of 102 VLA models, categorizing them by architecture and methodology, which provides a structured overview of the current l... |
| [Do Vision-Language Models Have Internal World Models Towards an Atomic Evaluation](https://arxiv.org/html/2506.21876v1) | 2025-06-27 | Robotics, Survey | The paper introduces WM-ABench, a benchmark designed to evaluate VLMs across 23 dimensions of world modeling, divided into perception and prediction stages. Methodologically, the authors propose a ... |
| [Advances and Challenges in Foundation Agents From Brain-Inspired Intelligence to Evolutionary, Collaborative, and Safe Systems](https://arxiv.org/abs/2504.01990) | 2025-03-31 | Survey |  |
| [Humanoid Locomotion and Manipulation Current Progress and Challenges in Control, Planning, and Learning co-corresponding authors](https://arxiv.org/html/2501.02116v1) | 2025-01-03 | Humanoid, Survey | The primary contributions of the paper include the introduction of a unified framework that integrates model-based control with learning-based approaches, allowing for improved performance in loco-... |
| [Understanding World or Predicting Future A Comprehensive Survey of World Models](https://arxiv.org/html/2411.14499v2) | 2024-11-21 | Modeling & World Models, Survey | The paper contributes a novel categorization framework for world models that emphasizes both implicit representations for understanding and predictive models for forecasting future states. The auth... |

## Tactile

*3 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [UniTac Whole-Robot Touch Sensing Without Tactile Sensors](https://arxiv.org/html/2507.07980v1) | 2025-07-10 | Tactile | The primary contributions of this work include the development of a data-driven model, UniTac, that utilizes built-in joint torque sensors for real-time whole-body touch sensing across various robo... |
| [ViTacFormer - Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation](https://roboverseorg.github.io/ViTacFormerPage/) | 2025-06-19 | Manipulation, Tactile, VLM & VLA |  |
| [Reactive Diffusion Policy Slow-Fast Visual-Tactile Policy Learning for Contact-Rich Manipulation](https://arxiv.org/html/2503.02881v3) | 2025-03-03 | Diffusion & Flow, Imitation Learning, Manipulation, Tactile | The primary contributions of this work include the development of the TactAR teleoperation system, which facilitates real-time tactile feedback through Augmented Reality, and the Reactive Diffusion... |

## VLM & VLA

*57 papers*

| Paper | Date | Categories | Contribution |
|-------|------|------------|--------------|
| [GR-3 Technical Report](https://arxiv.org/html/2507.15493v2) | 2025-07-22 | VLM & VLA | The paper introduces the GR-3 model, a large-scale vision-language-action framework that leverages co-training on vast datasets to enhance generalization. Key contributions include a multi-faceted ... |
| [Hierarchical Reasoning Model](https://arxiv.org/html/2506.21734v2) | 2025-07-22 | VLM & VLA | The primary contributions of the paper include the introduction of the HRM architecture, which consists of two interdependent recurrent modules: a high-level module for abstract reasoning and a low... |
| [Being-H0 Vision-Language-Action Pretraining from Large-Scale Human Videos](https://arxiv.org/html/2507.15597v1) | 2025-07-21 | VLM & VLA | The paper presents several key contributions, including the introduction of Physical Instruction Tuning, a novel paradigm that combines VLA pretraining from human videos with physical space alignme... |
| [Vision Language Action Models in Robotic Manipulation A Systematic Review](https://arxiv.org/html/2507.10672v1) | 2025-07-14 | Survey, VLM & VLA | The paper presents several key contributions: 1) A comprehensive analysis of 102 VLA models, categorizing them by architecture and methodology, which provides a structured overview of the current l... |
| [A Careful Examination of Large Behavior Models for Multitask Dexterous Manipulation](https://arxiv.org/html/2507.05331v1) | 2025-07-07 | LBM, VLM & VLA | The primary contributions of the paper include the introduction of a novel evaluation pipeline for LBMs that combines both simulated and real-world data, demonstrating that multi-task pretraining s... |
| [DreamVLA - A Vision-Language-Action Model Dreamed with Comprehensive World Knowledge](https://arxiv.org/html/2507.04447v1) | 2025-07-06 | VLM & VLA | The primary contributions of the paper include the introduction of DreamVLA, a novel framework that incorporates comprehensive world knowledge forecasting into existing VLA models. The authors prop... |
| [TriVLA - A Triple-System-Based Unified Vision-Language-Action Model for General Robot Control](https://arxiv.org/html/2507.01424v2) | 2025-07-02 | VLM & VLA | The primary technical contributions of the paper include the introduction of the TriVLA model, which employs a novel triple-system architecture comprising a Vision-Language Module (System 2), a Dyn... |
| [Geometry-aware 4D Video Generation for Robot Manipulation](https://arxiv.org/html/2507.01099v1) | 2025-07-01 | Modeling & World Models, VLM & VLA | This work introduces a novel 4D video generation framework that integrates temporal modeling with robust 3D geometric consistency by enforcing cross-view pointmap alignment. Key contributions inclu... |
| [WorldVLA Towards Autoregressive Action World Model](https://arxiv.org/html/2506.21539v1) | 2025-06-26 | Modeling & World Models, VLM & VLA | The primary contributions of the paper include the introduction of WorldVLA, which integrates the strengths of VLA and world models into a single framework. The authors propose a novel attention ma... |
| Gemini Robotics On-Device brings AI to local robotic devices | 2025-06-24 | VLM & VLA | The primary contributions of the paper include the introduction of the Gemini Robotics On-Device model, which is optimized for local execution on robotic devices, allowing for low-latency inference... |
| [Scaffolding Dexterous Manipulation with Vision-Language Models](https://arxiv.org/html/2506.19212v1) | 2025-06-24 | Manipulation, Modeling & World Models, VLM & VLA | The key contributions of this paper include the introduction of a novel framework that integrates vision-language models (VLMs) for generating coarse motion plans or "scaffolds" for dexterous manip... |
| [Unified Vision-Language-Action Model](https://arxiv.org/html/2506.19850v1) | 2025-06-24 | Modeling & World Models, VLM & VLA | The main contributions of the paper include the introduction of UniVLA, a novel unified vision-language-action model that encodes vision, language, and action as discrete tokens within a shared voc... |
| [Transferring Latent Motion Across Time for Multi-Frame Prediction in Manipulation](https://arxiv.org/html/2506.19816v1) | 2025-06-24 | VLM & VLA | The primary contributions of this paper include the introduction of CronusVLA, a unified framework that extends vision-language-action models to a multi-frame paradigm. Key innovations include a mu... |
| [RoboMonkey - Scaling Test-Time Sampling and Verification for Vision-Language-Action Models](https://arxiv.org/html/2506.17811v2) | 2025-06-21 | VLM & VLA | The paper introduces RoboMonkey, a novel framework for test-time scaling that leverages sampling and verification to enhance VLA robustness. Key contributions include the establishment of inference... |
| [ControlVLA Few-shot Object-centric Adaptation for Pre-trained Vision-Language-Action Models](https://arxiv.org/html/2506.16211v1) | 2025-06-19 | VLM & VLA | The paper introduces ControlVLA, a novel framework that effectively combines pre-trained VLA models with object-centric representations through a ControlNet-style architecture. This integration all... |
| [ViTacFormer - Learning Cross-Modal Representation for Visuo-Tactile Dexterous Manipulation](https://roboverseorg.github.io/ViTacFormerPage/) | 2025-06-19 | Manipulation, Tactile, VLM & VLA |  |
| [GR00T N1.5](https://research.nvidia.com/labs/gear/gr00t-n1_5/) | 2025-06-11 | VLM & VLA | The primary contributions of the paper include the architectural enhancements made to the VLM (Vision-Language Model) that now features a simplified adapter MLP and improved grounding capabilities ... |
| [Real-Time Execution of Action Chunking Flow Policies](https://arxiv.org/html/2506.07339v1) | 2025-06-09 | VLM & VLA | The paper introduces a novel algorithm termed Real-Time Chunking (RTC), which allows for asynchronous execution of action policies by generating the next chunk of actions while executing the curren... |
| [SmolVLA A vision-language-action model for affordable and efficient robotics](https://arxiv.org/html/2506.01844v1) | 2025-06-02 | VLM & VLA | The primary contributions of this work include the introduction of SmolVLA, a lightweight architecture designed for efficient training on consumer-grade GPUs, and the incorporation of community-col... |
| [Unified World Models Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets](https://arxiv.org/html/2504.02792v3) | 2025-05-23 | Modeling & World Models, VLM & VLA | The paper introduces Unified World Models (UWM), a framework that integrates action and video diffusion processes within a unified transformer architecture, enabling the effective pretraining of po... |
| [Interactive Post-Training for Vision-Language-Action Models](https://arxiv.org/html/2505.17016v1) | 2025-05-22 | VLM & VLA | The primary contribution of the paper is the introduction of RIPT-VLA, a reinforcement learning-based interactive post-training framework designed to fine-tune pretrained VLA models using sparse bi... |
| [FLARE - Robot Learning with Implicit World Modeling](https://research.nvidia.com/labs/gear/flare/) | 2025-05-22 | Modeling & World Models, VLM & VLA | The paper introduces FLARE (Future Latent Representation Alignment), a novel approach that simplifies the world modeling process by teaching robots to predict compact embeddings of future states ra... |
| [SpatialVLA Exploring Spatial Representations for Visual-Language-Action Model](https://arxiv.org/html/2501.15830v5) | 2025-05-19 | VLM & VLA | The paper introduces the SpatialVLA model, which innovatively incorporates Ego3D Position Encoding and Adaptive Action Grids to facilitate better spatial awareness in robotic manipulation. Key find... |
| [FastVLM Efficient Vision Encoding for Vision Language Models](https://arxiv.org/html/2412.13303v2) | 2025-05-15 | VLM & VLA | The primary contributions of this work include the introduction of FastVLM, which incorporates a novel hybrid vision encoder called FastViTHD, designed to output fewer tokens while significantly re... |
| [Learning to Act Anywhere with Task-centric Latent Actions](https://arxiv.org/html/2505.06111v2) | 2025-05-15 | VLM & VLA | The primary contributions of the paper include the introduction of UniVLA, a framework that learns task-centric latent action representations from web-scale, action-free videos, enabling cross-embo... |
| [Latent Action Pretraining From Videos](https://arxiv.org/html/2410.11758v2) | 2025-05-15 | VLM & VLA | The primary contributions include the introduction of Latent Action Pretraining (LAPA), which allows for unsupervised learning of latent actions from videos, thereby circumventing the need for grou... |
| [Diffusion-VLA Generalizable and Interpretable Robot Foundation Model via Self-Generated Reasoning](https://arxiv.org/html/2412.03293v2) | 2025-05-13 | Modeling & World Models, VLM & VLA | The primary contributions include the introduction of the DiffusionVLA (DiVLA) framework, which combines autoregressive reasoning and diffusion models, and a reasoning injection module that embeds ... |
| [VLATest - Testing and Evaluating Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/html/2409.12894v2) | 2025-05-09 | VLM & VLA | One of the primary contributions of the paper is the introduction of VLATest, a fuzzing framework that systematically generates testing scenes for assessing VLA models. The empirical study conducte... |
| [GraspVLA a Grasping Foundation Model Pre-trained on Billion-scale Synthetic Action Data](https://arxiv.org/html/2505.03233v2) | 2025-05-06 | VLM & VLA | This work introduces GraspVLA, a foundational model pre-trained exclusively on the SynGrasp-1B dataset, which consists of a billion synthetic grasping frames. Key contributions include the developm... |
| [When Pre-trained Visual Representations Fall Short Limitations in Visuo-motor Robot Learning](https://arxiv.org/html/2502.03270) | 2025-05-05 | Safety and Robustness, VLM & VLA | The primary contributions of the paper include a novel approach that enhances PVRs by incorporating temporal perception and task completion awareness, which the authors claim leads to significant p... |
| [From Foresight to Forethought - VLM-In-the-Loop Policy Steering via Latent Alignment](https://yilin-wu98.github.io/forewarn/) | 2025-05-02 | VLM & VLA | The primary contribution of the paper is the introduction of the FOREWARN framework, which effectively decouples foresight from forethought in the context of robot policy steering. The method utili... |
| [Fine-Tuning Vision-Language-Action Models Optimizing Speed and Success](https://arxiv.org/html/2502.19645v2) | 2025-04-28 | Finetuning, VLM & VLA | The authors introduce an Optimized Fine-Tuning (OFT) approach that integrates parallel decoding, action chunking, continuous action representations, and a simple L1 regression objective. These meth... |
| [NORA A Small Open-Sourced Generalist Vision Language Action Model for Embodied Tasks](https://arxiv.org/html/2504.19854) | 2025-04-28 | VLM & VLA | NORA, the proposed model, introduces a 3 billion parameter framework designed to significantly lower computational demands while enhancing task execution capabilities. It leverages the Qwen-2.5-VL-... |
| [Unified Video Action Model](https://arxiv.org/html/2503.00200v3) | 2025-04-24 | VLM & VLA | The paper presents several key contributions: first, the introduction of a unified latent representation that captures both video and action data, enabling simultaneous training and enhanced unders... |
| [𝜋_0.5 - a Vision-Language-Action Model with Open-World Generalization](https://arxiv.org/html/2504.16054v1) | 2025-04-22 | VLM & VLA | The paper introduces the π0.5 model, which utilizes a co-training framework that integrates diverse data sources, including robotic demonstrations, web data, and semantic predictions, to enhance ge... |
| [ConRFT A Reinforced Fine-tuning Method for VLA Models via Consistency Policy](https://arxiv.org/html/2502.05450v2) | 2025-04-14 | Finetuning, RL, VLM & VLA | The paper introduces a novel reinforced fine-tuning approach named ConRFT, which integrates both offline and online fine-tuning stages using a unified consistency-based training objective. Key cont... |
| [CoT-VLA Visual Chain-of-Thought Reasoning for Vision-Language-Action Models](https://arxiv.org/html/2503.22020v1) | 2025-03-27 | VLM & VLA | The primary contributions of the paper include the introduction of CoT reasoning through subgoal image generation, which serves as an interpretable intermediate representation for robotic control. ... |
| [GR00T N1 An Open Foundation Model for Generalist Humanoid Robots](https://arxiv.org/html/2503.14734v2) | 2025-03-27 | VLM & VLA | The paper introduces GR00T N1, a Vision-Language-Action (VLA) model featuring a dual-system architecture that integrates both a Vision-Language Model (System 2) and a Diffusion Transformer (System ... |
| Introducing Gemini Robotics and Gemini Robotics-ER, AI models designed for robots to understand, act and react to the physical world. | 2025-03-12 | VLM & VLA | The paper makes significant contributions by introducing Gemini Robotics and Gemini Robotics-ER, both built on Gemini 2.0 architecture. These models enhance generality, interactivity, and dexterity... |
| [Towards Generalizable Vision-Language Robotic Manipulation A Benchmark and LLM-guided 3D Policy](https://arxiv.org/html/2410.01345v2) | 2025-03-01 | Benchmarks, VLM & VLA | The key contributions include the introduction of GemBench, a novel benchmark designed to assess the generalization abilities of vision-language robotic manipulation policies across four levels of ... |
| [Hi Robot Open-Ended Instruction Following with Hierarchical Vision-Language-Action Models](https://arxiv.org/html/2502.19417v1) | 2025-02-26 | Manipulation, VLM & VLA | The primary contributions of this paper include the introduction of a hierarchical vision-language-action (VLA) model that allows robots to process complex prompts and incorporate user feedback eff... |
| [FAST Efficient Action Tokenization for Vision-Language-Action Models](https://arxiv.org/html/2501.09747v1) | 2025-01-16 | VLM & VLA | The primary contributions of the paper include the introduction of a novel compression-based tokenization scheme called Frequency-space Action Sequence Tokenization (FAST), which utilizes the discr... |
| [LongVILA Scaling Long-Context Visual Language Models for Long Videos](https://arxiv.org/html/2408.10188v6) | 2024-12-13 | VLM & VLA | The paper introduces LongVILA, a full-stack solution that incorporates algorithmic advancements and system optimizations to extend VLM capabilities from 8 frames to 2048 frames. It introduces a fiv... |
| [TinyVLA Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation](https://arxiv.org/html/2409.12514v4) | 2024-11-14 | VLM & VLA | The primary contributions of the paper include the introduction of TinyVLA, a compact VLA model (422M-1.3B) that significantly improves inference speed and data efficiency by utilizing smaller mult... |
| [𝜋₀ - A Vision-Language-Action Flow Model for General Robot Control](https://arxiv.org/html/2410.24164v3) | 2024-11-13 | VLM & VLA | The paper introduces a novel flow matching architecture built upon a pre-trained vision-language model, enabling robots to inherit extensive semantic knowledge. Its primary contributions include th... |
| [CLIP-RT Learning Language-Conditioned Robotic Policies from Natural Language Supervision](https://clip-rt.github.io/) | 2024-11-01 | Imitation Learning, VLM & VLA | The primary contributions include the introduction of the CLIP-RT model, which utilizes a vision-language-action framework to learn from natural language instructions. The paper demonstrates that C... |
| [PaliGemma A versatile 3B VLM for transfer](https://arxiv.org/html/2407.07726v2) | 2024-10-10 | VLM & VLA | The primary contributions include the introduction of PaliGemma, a compact yet powerful VLM that leverages a SigLIP-So400m vision encoder and a Gemma-2B language model. This architecture is designe... |
| [GR-2 - A Generative Video-Language-Action Model with Web-Scale Knowledge for Robot Manipulation](https://arxiv.org/html/2410.06158v1) | 2024-10-08 | VLM & VLA | The primary contributions of the paper include the introduction of a novel model architecture that integrates language conditioning for manipulation tasks and the implementation of a two-stage trai... |
| [Run-time Observation Interventions Make Vision-Language-Action Models More Visually Robust](https://arxiv.org/html/2410.01971v1) | 2024-10-02 | VLM & VLA | The paper introduces Bring Your Own VLA (BYOVLA), a novel run-time intervention scheme that dynamically identifies task-irrelevant regions in visual inputs and minimally alters them to enhance mode... |
| [OpenVLA - An Open-Source Vision-Language-Action Model](https://arxiv.org/html/2406.09246v3) | 2024-09-05 | VLM & VLA | The primary contributions of the paper include the introduction of OpenVLA, a 7B-parameter open-source VLA model that significantly outperforms existing closed models in various robotic tasks. The ... |
| [Octo An Open-Source Generalist Robot Policy](https://arxiv.org/abs/2405.12213) | 2024-05-26 | VLM & VLA | The authors introduce Octo, a transformer-based policy trained on 800,000 trajectories from the Open X-Embodiment dataset, which is noted as the largest dataset for robot manipulation to date. Key ... |
| [Prismatic VLMs Investigating the Design Space of Visually-Conditioned Language Models](https://arxiv.org/html/2402.07865v2) | 2024-05-03 | VLM & VLA | The paper contributes a cohesive framework for evaluating VLMs and presents three key resources: a standardized evaluation suite, optimized training code, and model checkpoints. The evaluation suit... |
| [Yell At Your Robot - Improving On-the-Fly from Language Corrections](https://arxiv.org/html/2403.12910v1) | 2024-03-19 | Manipulation, VLM & VLA | The primary contributions of the paper include the development of the Yell At Your Robot (YAY Robot) system, which integrates human language feedback to continuously improve robot performance in re... |
| [Open X-Embodiment Robotic Learning Datasets and RT-X Models](https://arxiv.org/html/2310.08864v8) | 2023-10-13 | Datasets, VLM & VLA | The authors present the Open X-Embodiment Repository, a comprehensive dataset containing over 1 million trajectories from 22,222 robotic embodiments across 21 institutions, which facilitates the ex... |
| [RT-2-X - Scaling up learning across many different robot types](https://deepmind.google/discover/blog/scaling-up-learning-across-many-different-robot-types/) | 2023-10-03 | VLM & VLA | The primary contributions include the development of the Open X-Embodiment dataset, which aggregates data from 22 different robot types, and the RT-1-X robotics transformer model, which enables kno... |
| [RT-2 Vision-Language-Action Models Transfer Web Knowledge to Robotic Control](https://arxiv.org/abs/2307.15818) | 2023-07-28 | VLM & VLA | The paper introduces a new category of models called vision-language-action (VLA) models, exemplified by RT-2, which directly fine-tune pre-trained VLMs to output low-level robotic actions represen... |
| [PaLM-E An Embodied Multimodal Language Model](https://arxiv.org/abs/2303.03378) | 2023-03-06 | VLM & VLA | The paper introduces PaLM-E, an embodied multimodal language model that integrates continuous sensor data with textual inputs, demonstrating significant improvement in various embodied reasoning ta... |

